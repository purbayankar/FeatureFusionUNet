{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "DeconvUNet.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/purbayankar/FeatureFusionUNet/blob/main/DeconvUNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxcLflB9uMT8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c330c8c-f06d-419a-bc51-632e7b8c236c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBK-VDWitCCD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8476a91-8169-4b80-cb21-bbfc94c2f951"
      },
      "source": [
        "# Imports\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.autograd import Variable\n",
        "import torchvision.transforms as tr\n",
        "\n",
        "# Models\n",
        "# from unet import Unet\n",
        "# from siamunet_conc import SiamUnet_conc\n",
        "# from siamunet_diff import SiamUnet_diff\n",
        "# from fresunet import FresUNet\n",
        "\n",
        "# Other\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "from skimage import io\n",
        "from scipy.ndimage import zoom\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from tqdm import tqdm as tqdm\n",
        "from pandas import read_csv\n",
        "from math import floor, ceil, sqrt, exp\n",
        "from IPython import display\n",
        "import time\n",
        "from itertools import chain\n",
        "import time\n",
        "import warnings\n",
        "from pprint import pprint\n",
        "\n",
        "\n",
        "\n",
        "print('IMPORTS OK')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IMPORTS OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RPcV8BktCCW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a71ffdaa-1673-488d-9133-381e0c646ae2"
      },
      "source": [
        "# Global Variables' Definitions\n",
        "\n",
        "PATH_TO_DATASET = '/content/drive/My Drive/OneraDataset_Images/'\n",
        "IS_PROTOTYPE = False\n",
        "\n",
        "FP_MODIFIER = 10 # Tuning parameter, use 1 if unsure\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "PATCH_SIDE = 96\n",
        "N_EPOCHS = 50\n",
        "\n",
        "NORMALISE_IMGS = True\n",
        "\n",
        "TRAIN_STRIDE = int(PATCH_SIDE/2) - 1\n",
        "\n",
        "TYPE = 3 # 0-RGB | 1-RGBIr | 2-All bands s.t. resulution <= 20m | 3-All bands\n",
        "\n",
        "LOAD_TRAINED = False\n",
        "\n",
        "DATA_AUG = True\n",
        "\n",
        "\n",
        "print('DEFINITIONS OK')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DEFINITIONS OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgI-4LV3tCCj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97c3b30c-df39-4e58-f0f7-2e0c45179705"
      },
      "source": [
        "# Functions\n",
        "\n",
        "def adjust_shape(I, s):\n",
        "    \"\"\"Adjust shape of grayscale image I to s.\"\"\"\n",
        "    \n",
        "    # crop if necesary\n",
        "    I = I[:s[0],:s[1]]\n",
        "    si = I.shape\n",
        "    \n",
        "    # pad if necessary \n",
        "    p0 = max(0,s[0] - si[0])\n",
        "    p1 = max(0,s[1] - si[1])\n",
        "    \n",
        "    return np.pad(I,((0,p0),(0,p1)),'edge')\n",
        "    \n",
        "\n",
        "def read_sentinel_img(path):\n",
        "    \"\"\"Read cropped Sentinel-2 image: RGB bands.\"\"\"\n",
        "    im_name = os.listdir(path)[0][:-7]\n",
        "    r = io.imread(path + im_name + \"B04.tif\")\n",
        "    g = io.imread(path + im_name + \"B03.tif\")\n",
        "    b = io.imread(path + im_name + \"B02.tif\")\n",
        "    \n",
        "    I = np.stack((r,g,b),axis=2).astype('float')\n",
        "    \n",
        "    if NORMALISE_IMGS:\n",
        "        I = (I - I.mean()) / I.std()\n",
        "\n",
        "    return I\n",
        "\n",
        "def read_sentinel_img_4(path):\n",
        "    \"\"\"Read cropped Sentinel-2 image: RGB and NIR bands.\"\"\"\n",
        "    im_name = os.listdir(path)[0][:-7]\n",
        "    r = io.imread(path + im_name + \"B04.tif\")\n",
        "    g = io.imread(path + im_name + \"B03.tif\")\n",
        "    b = io.imread(path + im_name + \"B02.tif\")\n",
        "    nir = io.imread(path + im_name + \"B08.tif\")\n",
        "    \n",
        "    I = np.stack((r,g,b,nir),axis=2).astype('float')\n",
        "    \n",
        "    if NORMALISE_IMGS:\n",
        "        I = (I - I.mean()) / I.std()\n",
        "\n",
        "    return I\n",
        "\n",
        "def read_sentinel_img_leq20(path):\n",
        "    \"\"\"Read cropped Sentinel-2 image: bands with resolution less than or equals to 20m.\"\"\"\n",
        "    im_name = os.listdir(path)[0][:-7]\n",
        "    \n",
        "    r = io.imread(path + im_name + \"B04.tif\")\n",
        "    s = r.shape\n",
        "    g = io.imread(path + im_name + \"B03.tif\")\n",
        "    b = io.imread(path + im_name + \"B02.tif\")\n",
        "    nir = io.imread(path + im_name + \"B08.tif\")\n",
        "    \n",
        "    ir1 = adjust_shape(zoom(io.imread(path + im_name + \"B05.tif\"),2),s)\n",
        "    ir2 = adjust_shape(zoom(io.imread(path + im_name + \"B06.tif\"),2),s)\n",
        "    ir3 = adjust_shape(zoom(io.imread(path + im_name + \"B07.tif\"),2),s)\n",
        "    nir2 = adjust_shape(zoom(io.imread(path + im_name + \"B8A.tif\"),2),s)\n",
        "    swir2 = adjust_shape(zoom(io.imread(path + im_name + \"B11.tif\"),2),s)\n",
        "    swir3 = adjust_shape(zoom(io.imread(path + im_name + \"B12.tif\"),2),s)\n",
        "    \n",
        "    I = np.stack((r,g,b,nir,ir1,ir2,ir3,nir2,swir2,swir3),axis=2).astype('float')\n",
        "    \n",
        "    if NORMALISE_IMGS:\n",
        "        I = (I - I.mean()) / I.std()\n",
        "\n",
        "    return I\n",
        "\n",
        "def read_sentinel_img_leq60(path):\n",
        "    \"\"\"Read cropped Sentinel-2 image: all bands.\"\"\"\n",
        "    im_name = os.listdir(path)[0][:-7]\n",
        "    \n",
        "    r = io.imread(path + im_name + \"B04.tif\")\n",
        "    s = r.shape\n",
        "    g = io.imread(path + im_name + \"B03.tif\")\n",
        "    b = io.imread(path + im_name + \"B02.tif\")\n",
        "    nir = io.imread(path + im_name + \"B08.tif\")\n",
        "    \n",
        "    ir1 = adjust_shape(zoom(io.imread(path + im_name + \"B05.tif\"),2),s)\n",
        "    ir2 = adjust_shape(zoom(io.imread(path + im_name + \"B06.tif\"),2),s)\n",
        "    ir3 = adjust_shape(zoom(io.imread(path + im_name + \"B07.tif\"),2),s)\n",
        "    nir2 = adjust_shape(zoom(io.imread(path + im_name + \"B8A.tif\"),2),s)\n",
        "    swir2 = adjust_shape(zoom(io.imread(path + im_name + \"B11.tif\"),2),s)\n",
        "    swir3 = adjust_shape(zoom(io.imread(path + im_name + \"B12.tif\"),2),s)\n",
        "    \n",
        "    uv = adjust_shape(zoom(io.imread(path + im_name + \"B01.tif\"),6),s)\n",
        "    wv = adjust_shape(zoom(io.imread(path + im_name + \"B09.tif\"),6),s)\n",
        "    swirc = adjust_shape(zoom(io.imread(path + im_name + \"B10.tif\"),6),s)\n",
        "    \n",
        "    I = np.stack((r,g,b,nir,ir1,ir2,ir3,nir2,swir2,swir3,uv,wv,swirc),axis=2).astype('float')\n",
        "    \n",
        "    if NORMALISE_IMGS:\n",
        "        I = (I - I.mean()) / I.std()\n",
        "\n",
        "    return I\n",
        "\n",
        "def read_sentinel_img_trio(path):\n",
        "    \"\"\"Read cropped Sentinel-2 image pair and change map.\"\"\"\n",
        "#     read images\n",
        "    if TYPE == 0:\n",
        "        I1 = read_sentinel_img(path + '/imgs_1/')\n",
        "        I2 = read_sentinel_img(path + '/imgs_2/')\n",
        "    elif TYPE == 1:\n",
        "        I1 = read_sentinel_img_4(path + '/imgs_1/')\n",
        "        I2 = read_sentinel_img_4(path + '/imgs_2/')\n",
        "    elif TYPE == 2:\n",
        "        I1 = read_sentinel_img_leq20(path + '/imgs_1/')\n",
        "        I2 = read_sentinel_img_leq20(path + '/imgs_2/')\n",
        "    elif TYPE == 3:\n",
        "        I1 = read_sentinel_img_leq60(path + '/imgs_1/')\n",
        "        I2 = read_sentinel_img_leq60(path + '/imgs_2/')\n",
        "        \n",
        "    cm = io.imread(path + '/cm/cm.png', as_gray=True) != 0\n",
        "    \n",
        "    # crop if necessary\n",
        "    s1 = I1.shape\n",
        "    s2 = I2.shape\n",
        "    I2 = np.pad(I2,((0, s1[0] - s2[0]), (0, s1[1] - s2[1]), (0,0)),'edge')\n",
        "    \n",
        "    \n",
        "    return I1, I2, cm\n",
        "\n",
        "\n",
        "\n",
        "def reshape_for_torch(I):\n",
        "    \"\"\"Transpose image for PyTorch coordinates.\"\"\"\n",
        "#     out = np.swapaxes(I,1,2)\n",
        "#     out = np.swapaxes(out,0,1)\n",
        "#     out = out[np.newaxis,:]\n",
        "    out = I.transpose((2, 0, 1))\n",
        "    return torch.from_numpy(out)\n",
        "\n",
        "\n",
        "\n",
        "class ChangeDetectionDataset(Dataset):\n",
        "    \"\"\"Change Detection dataset class, used for both training and test data.\"\"\"\n",
        "\n",
        "    def __init__(self, path, train = True, patch_side = 96, stride = None, use_all_bands = False, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        \n",
        "        # basics\n",
        "        self.transform = transform\n",
        "        self.path = path\n",
        "        self.patch_side = patch_side\n",
        "        if not stride:\n",
        "            self.stride = 1\n",
        "        else:\n",
        "            self.stride = stride\n",
        "        \n",
        "        if train:\n",
        "            fname = 'train.txt'\n",
        "        else:\n",
        "            fname = 'test.txt'\n",
        "        \n",
        "#         print(path + fname)\n",
        "        self.names = read_csv(path + fname).columns\n",
        "        self.n_imgs = self.names.shape[0]\n",
        "        \n",
        "        n_pix = 0\n",
        "        true_pix = 0\n",
        "        \n",
        "        \n",
        "        # load images\n",
        "        self.imgs_1 = {}\n",
        "        self.imgs_2 = {}\n",
        "        self.change_maps = {}\n",
        "        self.n_patches_per_image = {}\n",
        "        self.n_patches = 0\n",
        "        self.patch_coords = []\n",
        "        for im_name in tqdm(self.names):\n",
        "            # load and store each image\n",
        "            I1, I2, cm = read_sentinel_img_trio(self.path + im_name)\n",
        "            self.imgs_1[im_name] = reshape_for_torch(I1)\n",
        "            self.imgs_2[im_name] = reshape_for_torch(I2)\n",
        "            self.change_maps[im_name] = cm\n",
        "            \n",
        "            s = cm.shape\n",
        "            n_pix += np.prod(s)\n",
        "            true_pix += cm.sum()\n",
        "            \n",
        "            # calculate the number of patches\n",
        "            s = self.imgs_1[im_name].shape\n",
        "            n1 = ceil((s[1] - self.patch_side + 1) / self.stride)\n",
        "            n2 = ceil((s[2] - self.patch_side + 1) / self.stride)\n",
        "            n_patches_i = n1 * n2\n",
        "            self.n_patches_per_image[im_name] = n_patches_i\n",
        "            self.n_patches += n_patches_i\n",
        "            \n",
        "            # generate path coordinates\n",
        "            for i in range(n1):\n",
        "                for j in range(n2):\n",
        "                    # coordinates in (x1, x2, y1, y2)\n",
        "                    current_patch_coords = (im_name, \n",
        "                                    [self.stride*i, self.stride*i + self.patch_side, self.stride*j, self.stride*j + self.patch_side],\n",
        "                                    [self.stride*(i + 1), self.stride*(j + 1)])\n",
        "                    self.patch_coords.append(current_patch_coords)\n",
        "                    \n",
        "        self.weights = [ FP_MODIFIER * 2 * true_pix / n_pix, 2 * (n_pix - true_pix) / n_pix]\n",
        "        \n",
        "        \n",
        "\n",
        "    def get_img(self, im_name):\n",
        "        return self.imgs_1[im_name], self.imgs_2[im_name], self.change_maps[im_name]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_patches\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        current_patch_coords = self.patch_coords[idx]\n",
        "        im_name = current_patch_coords[0]\n",
        "        limits = current_patch_coords[1]\n",
        "        centre = current_patch_coords[2]\n",
        "        \n",
        "        I1 = self.imgs_1[im_name][:, limits[0]:limits[1], limits[2]:limits[3]]\n",
        "        I2 = self.imgs_2[im_name][:, limits[0]:limits[1], limits[2]:limits[3]]\n",
        "        \n",
        "        label = self.change_maps[im_name][limits[0]:limits[1], limits[2]:limits[3]]\n",
        "        label = torch.from_numpy(1*np.array(label)).float()\n",
        "        \n",
        "        sample = {'I1': I1, 'I2': I2, 'label': label}\n",
        "        \n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample\n",
        "\n",
        "\n",
        "\n",
        "class RandomFlip(object):\n",
        "    \"\"\"Flip randomly the images in a sample.\"\"\"\n",
        "\n",
        "#     def __init__(self):\n",
        "#         return\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        I1, I2, label = sample['I1'], sample['I2'], sample['label']\n",
        "        \n",
        "        if random.random() > 0.5:\n",
        "            I1 =  I1.numpy()[:,:,::-1].copy()\n",
        "            I1 = torch.from_numpy(I1)\n",
        "            I2 =  I2.numpy()[:,:,::-1].copy()\n",
        "            I2 = torch.from_numpy(I2)\n",
        "            label =  label.numpy()[:,::-1].copy()\n",
        "            label = torch.from_numpy(label)\n",
        "\n",
        "        return {'I1': I1, 'I2': I2, 'label': label}\n",
        "\n",
        "\n",
        "\n",
        "class RandomRot(object):\n",
        "    \"\"\"Rotate randomly the images in a sample.\"\"\"\n",
        "\n",
        "#     def __init__(self):\n",
        "#         return\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        I1, I2, label = sample['I1'], sample['I2'], sample['label']\n",
        "        \n",
        "        n = random.randint(0, 3)\n",
        "        if n:\n",
        "            I1 =  sample['I1'].numpy()\n",
        "            I1 = np.rot90(I1, n, axes=(1, 2)).copy()\n",
        "            I1 = torch.from_numpy(I1)\n",
        "            I2 =  sample['I2'].numpy()\n",
        "            I2 = np.rot90(I2, n, axes=(1, 2)).copy()\n",
        "            I2 = torch.from_numpy(I2)\n",
        "            label =  sample['label'].numpy()\n",
        "            label = np.rot90(label, n, axes=(0, 1)).copy()\n",
        "            label = torch.from_numpy(label)\n",
        "\n",
        "        return {'I1': I1, 'I2': I2, 'label': label}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print('UTILS OK')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UTILS OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5l3hr1AtCCt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rDHwU5gtCC1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18c55830-b0b9-4be9-bf3a-3872ef6061c2"
      },
      "source": [
        "# Dataset\n",
        "\n",
        "\n",
        "if DATA_AUG:\n",
        "    data_transform = tr.Compose([RandomFlip(), RandomRot()])\n",
        "else:\n",
        "    data_transform = None\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "train_dataset = ChangeDetectionDataset(PATH_TO_DATASET, train = True, stride = TRAIN_STRIDE, transform=data_transform)\n",
        "weights = torch.FloatTensor(train_dataset.weights).cuda()\n",
        "print(weights)\n",
        "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 4)\n",
        "\n",
        "test_dataset = ChangeDetectionDataset(PATH_TO_DATASET, train = False, stride = TRAIN_STRIDE)\n",
        "test_loader = DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 4)\n",
        "\n",
        "\n",
        "print('DATASETS OK')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [02:20<00:00, 10.01s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor([0.4595, 1.9540], device='cuda:0')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [01:30<00:00,  9.01s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DATASETS OK\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7s94wymZtCDD"
      },
      "source": [
        "# print(weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWW5lFzfwfdD"
      },
      "source": [
        "**Deconvolution Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ev2Cn4VlwaDY"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "from torch.nn.modules import conv\n",
        "from torch.nn.modules.utils import _pair\n",
        "import math\n",
        "\n",
        "#iteratively solve for inverse sqrt of a matrix\n",
        "def isqrt_newton_schulz_autograd(A, numIters):\n",
        "    dim = A.shape[0]\n",
        "    normA=A.norm()\n",
        "    Y = A.div(normA)\n",
        "    I = torch.eye(dim,dtype=A.dtype,device=A.device)\n",
        "    Z = torch.eye(dim,dtype=A.dtype,device=A.device)\n",
        "\n",
        "    for i in range(numIters):\n",
        "        T = 0.5*(3.0*I - Z@Y)\n",
        "        Y = Y@T\n",
        "        Z = T@Z\n",
        "    #A_sqrt = Y*torch.sqrt(normA)\n",
        "    A_isqrt = Z / torch.sqrt(normA)\n",
        "    return A_isqrt\n",
        "\n",
        "def isqrt_newton_schulz_autograd_batch(A, numIters):\n",
        "    batchSize,dim,_ = A.shape\n",
        "    normA=A.view(batchSize, -1).norm(2, 1).view(batchSize, 1, 1)\n",
        "    Y = A.div(normA)\n",
        "    I = torch.eye(dim,dtype=A.dtype,device=A.device).unsqueeze(0).expand_as(A)\n",
        "    Z = torch.eye(dim,dtype=A.dtype,device=A.device).unsqueeze(0).expand_as(A)\n",
        "\n",
        "    for i in range(numIters):\n",
        "        T = 0.5*(3.0*I - Z.bmm(Y))\n",
        "        Y = Y.bmm(T)\n",
        "        Z = T.bmm(Z)\n",
        "    #A_sqrt = Y*torch.sqrt(normA)\n",
        "    A_isqrt = Z / torch.sqrt(normA)\n",
        "\n",
        "    return A_isqrt\n",
        "\n",
        "\n",
        "\n",
        "#deconvolve channels\n",
        "class ChannelDeconv(nn.Module):\n",
        "    def __init__(self,  block, eps=1e-2,n_iter=5,momentum=0.1,sampling_stride=3):\n",
        "        super(ChannelDeconv, self).__init__()\n",
        "\n",
        "        self.eps = eps\n",
        "        self.n_iter=n_iter\n",
        "        self.momentum=momentum\n",
        "        self.block = block\n",
        "\n",
        "        self.register_buffer('running_mean1', torch.zeros(block, 1))\n",
        "        #self.register_buffer('running_cov', torch.eye(block))\n",
        "        self.register_buffer('running_deconv', torch.eye(block))\n",
        "        self.register_buffer('running_mean2', torch.zeros(1, 1))\n",
        "        self.register_buffer('running_var', torch.ones(1, 1))\n",
        "        self.register_buffer('num_batches_tracked', torch.tensor(0, dtype=torch.long))\n",
        "        self.sampling_stride=sampling_stride\n",
        "    def forward(self, x):\n",
        "        x_shape = x.shape\n",
        "        if len(x.shape)==2:\n",
        "            x=x.view(x.shape[0],x.shape[1],1,1)\n",
        "        if len(x.shape)==3:\n",
        "            print('Error! Unsupprted tensor shape.')\n",
        "\n",
        "        N, C, H, W = x.size()\n",
        "        B = self.block\n",
        "\n",
        "        #take the first c channels out for deconv\n",
        "        c=int(C/B)*B\n",
        "        if c==0:\n",
        "            print('Error! block should be set smaller.')\n",
        "\n",
        "        #step 1. remove mean\n",
        "        if c!=C:\n",
        "            x1=x[:,:c].permute(1,0,2,3).contiguous().view(B,-1)\n",
        "        else:\n",
        "            x1=x.permute(1,0,2,3).contiguous().view(B,-1)\n",
        "\n",
        "        if self.sampling_stride > 1 and H >= self.sampling_stride and W >= self.sampling_stride:\n",
        "            x1_s = x1[:,::self.sampling_stride**2]\n",
        "        else:\n",
        "            x1_s=x1\n",
        "\n",
        "        mean1 = x1_s.mean(-1, keepdim=True)\n",
        "\n",
        "        if self.num_batches_tracked==0:\n",
        "            self.running_mean1.copy_(mean1.detach())\n",
        "        if self.training:\n",
        "            self.running_mean1.mul_(1-self.momentum)\n",
        "            self.running_mean1.add_(mean1.detach()*self.momentum)\n",
        "        else:\n",
        "            mean1 = self.running_mean1\n",
        "\n",
        "        x1=x1-mean1\n",
        "\n",
        "        #step 2. calculate deconv@x1 = cov^(-0.5)@x1\n",
        "        if self.training:\n",
        "            cov = x1_s @ x1_s.t() / x1_s.shape[1] + self.eps * torch.eye(B, dtype=x.dtype, device=x.device)\n",
        "            deconv = isqrt_newton_schulz_autograd(cov, self.n_iter)\n",
        "\n",
        "        if self.num_batches_tracked==0:\n",
        "            #self.running_cov.copy_(cov.detach())\n",
        "            self.running_deconv.copy_(deconv.detach())\n",
        "\n",
        "        if self.training:\n",
        "            #self.running_cov.mul_(1-self.momentum)\n",
        "            #self.running_cov.add_(cov.detach()*self.momentum)\n",
        "            self.running_deconv.mul_(1 - self.momentum)\n",
        "            self.running_deconv.add_(deconv.detach() * self.momentum)\n",
        "        else:\n",
        "            # cov = self.running_cov\n",
        "            deconv = self.running_deconv\n",
        "\n",
        "        x1 =deconv@x1\n",
        "\n",
        "        #reshape to N,c,J,W\n",
        "        x1 = x1.view(c, N, H, W).contiguous().permute(1,0,2,3)\n",
        "\n",
        "        # normalize the remaining channels\n",
        "        if c!=C:\n",
        "            x_tmp=x[:, c:].view(N,-1)\n",
        "            if self.sampling_stride > 1 and H>=self.sampling_stride and W>=self.sampling_stride:\n",
        "                x_s = x_tmp[:, ::self.sampling_stride ** 2]\n",
        "            else:\n",
        "                x_s = x_tmp\n",
        "\n",
        "            mean2=x_s.mean()\n",
        "            var=x_s.var()\n",
        "\n",
        "            if self.num_batches_tracked == 0:\n",
        "                self.running_mean2.copy_(mean2.detach())\n",
        "                self.running_var.copy_(var.detach())\n",
        "\n",
        "            if self.training:\n",
        "                self.running_mean2.mul_(1 - self.momentum)\n",
        "                self.running_mean2.add_(mean2.detach() * self.momentum)\n",
        "                self.running_var.mul_(1 - self.momentum)\n",
        "                self.running_var.add_(var.detach() * self.momentum)\n",
        "            else:\n",
        "                mean2 = self.running_mean2\n",
        "                var = self.running_var\n",
        "\n",
        "            x_tmp = (x[:, c:] - mean2) / (var + self.eps).sqrt()\n",
        "            x1 = torch.cat([x1, x_tmp], dim=1)\n",
        "\n",
        "\n",
        "        if self.training:\n",
        "            self.num_batches_tracked.add_(1)\n",
        "\n",
        "        if len(x_shape)==2:\n",
        "            x1=x1.view(x_shape)\n",
        "        return x1\n",
        "\n",
        "#An alternative implementation\n",
        "class Delinear(nn.Module):\n",
        "    __constants__ = ['bias', 'in_features', 'out_features']\n",
        "\n",
        "    def __init__(self, in_features, out_features, bias=True, eps=1e-5, n_iter=5, momentum=0.1, block=512):\n",
        "        super(Delinear, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\n",
        "        if bias:\n",
        "            self.bias = nn.Parameter(torch.Tensor(out_features))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        self.reset_parameters()\n",
        "\n",
        "\n",
        "\n",
        "        if block > in_features:\n",
        "            block = in_features\n",
        "        else:\n",
        "            if in_features%block!=0:\n",
        "                block=math.gcd(block,in_features)\n",
        "                print('block size set to:', block)\n",
        "        self.block = block\n",
        "        self.momentum = momentum\n",
        "        self.n_iter = n_iter\n",
        "        self.eps = eps\n",
        "        self.register_buffer('running_mean', torch.zeros(self.block))\n",
        "        self.register_buffer('running_deconv', torch.eye(self.block))\n",
        "\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
        "        if self.bias is not None:\n",
        "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
        "            bound = 1 / math.sqrt(fan_in)\n",
        "            nn.init.uniform_(self.bias, -bound, bound)\n",
        "\n",
        "    def forward(self, input):\n",
        "\n",
        "        if self.training:\n",
        "\n",
        "            # 1. reshape\n",
        "            X=input.view(-1, self.block)\n",
        "\n",
        "            # 2. subtract mean\n",
        "            X_mean = X.mean(0)\n",
        "            X = X - X_mean.unsqueeze(0)\n",
        "            self.running_mean.mul_(1 - self.momentum)\n",
        "            self.running_mean.add_(X_mean.detach() * self.momentum)\n",
        "\n",
        "            # 3. calculate COV, COV^(-0.5), then deconv\n",
        "            # Cov = X.t() @ X / X.shape[0] + self.eps * torch.eye(X.shape[1], dtype=X.dtype, device=X.device)\n",
        "            Id = torch.eye(X.shape[1], dtype=X.dtype, device=X.device)\n",
        "            Cov = torch.addmm(self.eps, Id, 1. / X.shape[0], X.t(), X)\n",
        "            deconv = isqrt_newton_schulz_autograd(Cov, self.n_iter)\n",
        "            # track stats for evaluation\n",
        "            self.running_deconv.mul_(1 - self.momentum)\n",
        "            self.running_deconv.add_(deconv.detach() * self.momentum)\n",
        "\n",
        "        else:\n",
        "            X_mean = self.running_mean\n",
        "            deconv = self.running_deconv\n",
        "\n",
        "        w = self.weight.view(-1, self.block) @ deconv\n",
        "        b = self.bias\n",
        "        if self.bias is not None:\n",
        "            b = b - (w @ (X_mean.unsqueeze(1))).view(self.weight.shape[0], -1).sum(1)\n",
        "        w = w.view(self.weight.shape)\n",
        "        return F.linear(input, w, b)\n",
        "\n",
        "    def extra_repr(self):\n",
        "        return 'in_features={}, out_features={}, bias={}'.format(\n",
        "            self.in_features, self.out_features, self.bias is not None\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "class FastDeconv(conv._ConvNd):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1,groups=1,bias=True, eps=1e-5, n_iter=5, momentum=0.1, block=64, sampling_stride=3,freeze=False,freeze_iter=100):\n",
        "        self.momentum = momentum\n",
        "        self.n_iter = n_iter\n",
        "        self.eps = eps\n",
        "        self.counter=0\n",
        "        self.track_running_stats=True\n",
        "        super(FastDeconv, self).__init__(\n",
        "            in_channels, out_channels,  _pair(kernel_size), _pair(stride), _pair(padding), _pair(dilation),\n",
        "            False, _pair(0), groups, bias, padding_mode='zeros')\n",
        "\n",
        "        if block > in_channels:\n",
        "            block = in_channels\n",
        "        else:\n",
        "            if in_channels%block!=0:\n",
        "                block=math.gcd(block,in_channels)\n",
        "\n",
        "        if groups>1:\n",
        "            #grouped conv\n",
        "            block=in_channels//groups\n",
        "\n",
        "        self.block=block\n",
        "\n",
        "        self.num_features = kernel_size**2 *block\n",
        "        if groups==1:\n",
        "            self.register_buffer('running_mean', torch.zeros(self.num_features))\n",
        "            self.register_buffer('running_deconv', torch.eye(self.num_features))\n",
        "        else:\n",
        "            self.register_buffer('running_mean', torch.zeros(kernel_size ** 2 * in_channels))\n",
        "            self.register_buffer('running_deconv', torch.eye(self.num_features).repeat(in_channels // block, 1, 1))\n",
        "\n",
        "        self.sampling_stride=sampling_stride*stride\n",
        "        self.counter=0\n",
        "        self.freeze_iter=freeze_iter\n",
        "        self.freeze=freeze\n",
        "\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.shape\n",
        "        B = self.block\n",
        "        frozen=self.freeze and (self.counter>self.freeze_iter)\n",
        "        if self.training and self.track_running_stats:\n",
        "            self.counter+=1\n",
        "            self.counter %= (self.freeze_iter * 10)\n",
        "\n",
        "        if self.training and (not frozen):\n",
        "\n",
        "            # 1. im2col: N x cols x pixels -> N*pixles x cols\n",
        "            if self.kernel_size[0]>1:\n",
        "                X = torch.nn.functional.unfold(x, self.kernel_size,self.dilation,self.padding,self.sampling_stride).transpose(1, 2).contiguous()\n",
        "            else:\n",
        "                #channel wise\n",
        "                X = x.permute(0, 2, 3, 1).contiguous().view(-1, C)[::self.sampling_stride**2,:]\n",
        "\n",
        "            if self.groups==1:\n",
        "                # (C//B*N*pixels,k*k*B)\n",
        "                X = X.view(-1, self.num_features, C // B).transpose(1, 2).contiguous().view(-1, self.num_features)\n",
        "            else:\n",
        "                X=X.view(-1,X.shape[-1])\n",
        "\n",
        "            # 2. subtract mean\n",
        "            X_mean = X.mean(0)\n",
        "            X = X - X_mean.unsqueeze(0)\n",
        "\n",
        "            # 3. calculate COV, COV^(-0.5), then deconv\n",
        "            if self.groups==1:\n",
        "                #Cov = X.t() @ X / X.shape[0] + self.eps * torch.eye(X.shape[1], dtype=X.dtype, device=X.device)\n",
        "                Id=torch.eye(X.shape[1], dtype=X.dtype, device=X.device)\n",
        "                Cov = torch.addmm(self.eps, Id, 1. / X.shape[0], X.t(), X)\n",
        "                deconv = isqrt_newton_schulz_autograd(Cov, self.n_iter)\n",
        "            else:\n",
        "                X = X.view(-1, self.groups, self.num_features).transpose(0, 1)\n",
        "                Id = torch.eye(self.num_features, dtype=X.dtype, device=X.device).expand(self.groups, self.num_features, self.num_features)\n",
        "                Cov = torch.baddbmm(self.eps, Id, 1. / X.shape[1], X.transpose(1, 2), X)\n",
        "\n",
        "                deconv = isqrt_newton_schulz_autograd_batch(Cov, self.n_iter)\n",
        "\n",
        "            if self.track_running_stats:\n",
        "                self.running_mean.mul_(1 - self.momentum)\n",
        "                self.running_mean.add_(X_mean.detach() * self.momentum)\n",
        "                # track stats for evaluation\n",
        "                self.running_deconv.mul_(1 - self.momentum)\n",
        "                self.running_deconv.add_(deconv.detach() * self.momentum)\n",
        "\n",
        "        else:\n",
        "            X_mean = self.running_mean\n",
        "            deconv = self.running_deconv\n",
        "\n",
        "        #4. X * deconv * conv = X * (deconv * conv)\n",
        "        if self.groups==1:\n",
        "            w = self.weight.view(-1, self.num_features, C // B).transpose(1, 2).contiguous().view(-1,self.num_features) @ deconv\n",
        "            b = self.bias - (w @ (X_mean.unsqueeze(1))).view(self.weight.shape[0], -1).sum(1)\n",
        "            w = w.view(-1, C // B, self.num_features).transpose(1, 2).contiguous()\n",
        "        else:\n",
        "            w = self.weight.view(C//B, -1,self.num_features)@deconv\n",
        "            b = self.bias - (w @ (X_mean.view( -1,self.num_features,1))).view(self.bias.shape)\n",
        "\n",
        "        w = w.view(self.weight.shape)\n",
        "        x= F.conv2d(x, w, b, self.stride, self.padding, self.dilation, self.groups)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBSQAxAutlpM"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.modules.padding import ReplicationPad2d\n",
        "\n",
        "class Unet(nn.Module):\n",
        "    \"\"\"EF segmentation network.\"\"\"\n",
        "\n",
        "    def __init__(self, input_nbr, label_nbr):\n",
        "        super(Unet, self).__init__()\n",
        "\n",
        "        self.input_nbr = input_nbr\n",
        "\n",
        "        self.conv11 = FastDeconv(input_nbr, 16, kernel_size=3, padding=1)\n",
        "        self.bn11 = nn.BatchNorm2d(16)\n",
        "        self.do11 = nn.Dropout2d(p=0.2)\n",
        "        self.conv12 = FastDeconv(16, 16, kernel_size=3, padding=1)\n",
        "        self.bn12 = nn.BatchNorm2d(16)\n",
        "        self.do12 = nn.Dropout2d(p=0.2)\n",
        "\n",
        "        self.conv21 = FastDeconv(16, 32, kernel_size=3, padding=1)\n",
        "        self.bn21 = nn.BatchNorm2d(32)\n",
        "        self.do21 = nn.Dropout2d(p=0.2)\n",
        "        self.conv22 = FastDeconv(32, 32, kernel_size=3, padding=1)\n",
        "        self.bn22 = nn.BatchNorm2d(32)\n",
        "        self.do22 = nn.Dropout2d(p=0.2)\n",
        "\n",
        "        self.conv31 = FastDeconv(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn31 = nn.BatchNorm2d(64)\n",
        "        self.do31 = nn.Dropout2d(p=0.2)\n",
        "        self.conv32 = FastDeconv(64, 64, kernel_size=3, padding=1)\n",
        "        self.bn32 = nn.BatchNorm2d(64)\n",
        "        self.do32 = nn.Dropout2d(p=0.2)\n",
        "        self.conv33 = FastDeconv(64, 64, kernel_size=3, padding=1)\n",
        "        self.bn33 = nn.BatchNorm2d(64)\n",
        "        self.do33 = nn.Dropout2d(p=0.2)\n",
        "\n",
        "        self.conv41 = FastDeconv(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn41 = nn.BatchNorm2d(128)\n",
        "        self.do41 = nn.Dropout2d(p=0.2)\n",
        "        self.conv42 = FastDeconv(128, 128, kernel_size=3, padding=1)\n",
        "        self.bn42 = nn.BatchNorm2d(128)\n",
        "        self.do42 = nn.Dropout2d(p=0.2)\n",
        "        self.conv43 = FastDeconv(128, 128, kernel_size=3, padding=1)\n",
        "        self.bn43 = nn.BatchNorm2d(128)\n",
        "        self.do43 = nn.Dropout2d(p=0.2)\n",
        "\n",
        "\n",
        "        self.upconv4 = nn.ConvTranspose2d(128, 128, kernel_size=3, padding=1, stride=2, output_padding=1)\n",
        "\n",
        "        self.conv43d = nn.ConvTranspose2d(256, 128, kernel_size=3, padding=1)\n",
        "        self.bn43d = nn.BatchNorm2d(128)\n",
        "        self.do43d = nn.Dropout2d(p=0.2)\n",
        "        self.conv42d = nn.ConvTranspose2d(128, 128, kernel_size=3, padding=1)\n",
        "        self.bn42d = nn.BatchNorm2d(128)\n",
        "        self.do42d = nn.Dropout2d(p=0.2)\n",
        "        self.conv41d = nn.ConvTranspose2d(128, 64, kernel_size=3, padding=1)\n",
        "        self.bn41d = nn.BatchNorm2d(64)\n",
        "        self.do41d = nn.Dropout2d(p=0.2)\n",
        "\n",
        "        self.upconv3 = nn.ConvTranspose2d(64, 64, kernel_size=3, padding=1, stride=2, output_padding=1)\n",
        "\n",
        "        self.conv33d = nn.ConvTranspose2d(128, 64, kernel_size=3, padding=1)\n",
        "        self.bn33d = nn.BatchNorm2d(64)\n",
        "        self.do33d = nn.Dropout2d(p=0.2)\n",
        "        self.conv32d = nn.ConvTranspose2d(64, 64, kernel_size=3, padding=1)\n",
        "        self.bn32d = nn.BatchNorm2d(64)\n",
        "        self.do32d = nn.Dropout2d(p=0.2)\n",
        "        self.conv31d = nn.ConvTranspose2d(64, 32, kernel_size=3, padding=1)\n",
        "        self.bn31d = nn.BatchNorm2d(32)\n",
        "        self.do31d = nn.Dropout2d(p=0.2)\n",
        "\n",
        "        self.upconv2 = nn.ConvTranspose2d(32, 32, kernel_size=3, padding=1, stride=2, output_padding=1)\n",
        "\n",
        "        self.conv22d = nn.ConvTranspose2d(64, 32, kernel_size=3, padding=1)\n",
        "        self.bn22d = nn.BatchNorm2d(32)\n",
        "        self.do22d = nn.Dropout2d(p=0.2)\n",
        "        self.conv21d = nn.ConvTranspose2d(32, 16, kernel_size=3, padding=1)\n",
        "        self.bn21d = nn.BatchNorm2d(16)\n",
        "        self.do21d = nn.Dropout2d(p=0.2)\n",
        "\n",
        "        self.upconv1 = nn.ConvTranspose2d(16, 16, kernel_size=3, padding=1, stride=2, output_padding=1)\n",
        "\n",
        "        self.conv12d = nn.ConvTranspose2d(32, 16, kernel_size=3, padding=1)\n",
        "        self.bn12d = nn.BatchNorm2d(16)\n",
        "        self.do12d = nn.Dropout2d(p=0.2)\n",
        "        self.conv11d = nn.ConvTranspose2d(16, label_nbr, kernel_size=3, padding=1)\n",
        "\n",
        "        self.sm = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "\n",
        "        x = torch.cat((x1, x2), 1)\n",
        "\n",
        "        \"\"\"Forward method.\"\"\"\n",
        "        # Stage 1\n",
        "        x11 = self.do11(F.relu(self.bn11(self.conv11(x))))\n",
        "        x12 = self.do12(F.relu(self.bn12(self.conv12(x11))))\n",
        "        x1p = F.max_pool2d(x12, kernel_size=2, stride=2)\n",
        "\n",
        "        # Stage 2\n",
        "        x21 = self.do21(F.relu(self.bn21(self.conv21(x1p))))\n",
        "        x22 = self.do22(F.relu(self.bn22(self.conv22(x21))))\n",
        "        x2p = F.max_pool2d(x22, kernel_size=2, stride=2)\n",
        "\n",
        "        # Stage 3\n",
        "        x31 = self.do31(F.relu(self.bn31(self.conv31(x2p))))\n",
        "        x32 = self.do32(F.relu(self.bn32(self.conv32(x31))))\n",
        "        x33 = self.do33(F.relu(self.bn33(self.conv33(x32))))\n",
        "        x3p = F.max_pool2d(x33, kernel_size=2, stride=2)\n",
        "\n",
        "        # Stage 4\n",
        "        x41 = self.do41(F.relu(self.bn41(self.conv41(x3p))))\n",
        "        x42 = self.do42(F.relu(self.bn42(self.conv42(x41))))\n",
        "        x43 = self.do43(F.relu(self.bn43(self.conv43(x42))))\n",
        "        x4p = F.max_pool2d(x43, kernel_size=2, stride=2)\n",
        "\n",
        "\n",
        "        # Stage 4d\n",
        "        x4d = self.upconv4(x4p)\n",
        "        pad4 = ReplicationPad2d((0, x43.size(3) - x4d.size(3), 0, x43.size(2) - x4d.size(2)))\n",
        "        x4d = torch.cat((pad4(x4d), x43), 1)\n",
        "        x43d = self.do43d(F.relu(self.bn43d(self.conv43d(x4d))))\n",
        "        x42d = self.do42d(F.relu(self.bn42d(self.conv42d(x43d))))\n",
        "        x41d = self.do41d(F.relu(self.bn41d(self.conv41d(x42d))))\n",
        "\n",
        "        # Stage 3d\n",
        "        x3d = self.upconv3(x41d)\n",
        "        pad3 = ReplicationPad2d((0, x33.size(3) - x3d.size(3), 0, x33.size(2) - x3d.size(2)))\n",
        "        x3d = torch.cat((pad3(x3d), x33), 1)\n",
        "        x33d = self.do33d(F.relu(self.bn33d(self.conv33d(x3d))))\n",
        "        x32d = self.do32d(F.relu(self.bn32d(self.conv32d(x33d))))\n",
        "        x31d = self.do31d(F.relu(self.bn31d(self.conv31d(x32d))))\n",
        "\n",
        "        # Stage 2d\n",
        "        x2d = self.upconv2(x31d)\n",
        "        pad2 = ReplicationPad2d((0, x22.size(3) - x2d.size(3), 0, x22.size(2) - x2d.size(2)))\n",
        "        x2d = torch.cat((pad2(x2d), x22), 1)\n",
        "        x22d = self.do22d(F.relu(self.bn22d(self.conv22d(x2d))))\n",
        "        x21d = self.do21d(F.relu(self.bn21d(self.conv21d(x22d))))\n",
        "\n",
        "        # Stage 1d\n",
        "        x1d = self.upconv1(x21d)\n",
        "        pad1 = ReplicationPad2d((0, x12.size(3) - x1d.size(3), 0, x12.size(2) - x1d.size(2)))\n",
        "        x1d = torch.cat((pad1(x1d), x12), 1)\n",
        "        x12d = self.do12d(F.relu(self.bn12d(self.conv12d(x1d))))\n",
        "        x11d = self.conv11d(x12d)\n",
        "\n",
        "        return self.sm(x11d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_-6nJdHtCDL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60cd30a2-a2d8-4921-c4c8-89fc32054a02"
      },
      "source": [
        "# 0-RGB | 1-RGBIr | 2-All bands s.t. resulution <= 20m | 3-All bands\n",
        "\n",
        "if TYPE == 0:\n",
        "    net, net_name = Unet(2*3, 2), 'FC-EF'\n",
        "#     net, net_name = SiamUnet_conc(3, 2), 'FC-Siam-conc'\n",
        "#     net, net_name = SiamUnet_diff(3, 2), 'FC-Siam-diff'\n",
        "    # net, net_name = FresUNet(2*3, 2), 'FresUNet'\n",
        "elif TYPE == 1:\n",
        "    net, net_name = Unet(2*4, 2), 'FC-EF'\n",
        "#     net, net_name = SiamUnet_conc(4, 2), 'FC-Siam-conc'\n",
        "#     net, net_name = SiamUnet_diff(4, 2), 'FC-Siam-diff'\n",
        "    # net, net_name = FresUNet(2*4, 2), 'FresUNet'\n",
        "elif TYPE == 2:\n",
        "    net, net_name = Unet(2*10, 2), 'FC-EF'\n",
        "#     net, net_name = SiamUnet_conc(10, 2), 'FC-Siam-conc'\n",
        "#     net, net_name = SiamUnet_diff(10, 2), 'FC-Siam-diff'\n",
        "#     net, net_name = FresUNet(2*10, 2), 'FresUNet'\n",
        "elif TYPE == 3:\n",
        "    net, net_name = Unet(2*13, 2), 'FC-EF'\n",
        "#     net, net_name = SiamUnet_conc(13, 2), 'FC-Siam-conc'\n",
        "#     net, net_name = SiamUnet_diff(13, 2), 'FC-Siam-diff'\n",
        "#     net, net_name = FresUNet(2*13, 2), 'FresUNet'\n",
        "\n",
        "\n",
        "net.cuda()\n",
        "\n",
        "criterion = nn.NLLLoss(weight=weights) # to be used with logsoftmax output\n",
        "from torchsummary import summary\n",
        "\n",
        "summary(net,input_size=[(13,256,256),(13,256,256)])\n",
        "\n",
        "print('NETWORK OK')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "        FastDeconv-1         [-1, 16, 256, 256]           3,760\n",
            "       BatchNorm2d-2         [-1, 16, 256, 256]              32\n",
            "         Dropout2d-3         [-1, 16, 256, 256]               0\n",
            "        FastDeconv-4         [-1, 16, 256, 256]           2,320\n",
            "       BatchNorm2d-5         [-1, 16, 256, 256]              32\n",
            "         Dropout2d-6         [-1, 16, 256, 256]               0\n",
            "        FastDeconv-7         [-1, 32, 128, 128]           4,640\n",
            "       BatchNorm2d-8         [-1, 32, 128, 128]              64\n",
            "         Dropout2d-9         [-1, 32, 128, 128]               0\n",
            "       FastDeconv-10         [-1, 32, 128, 128]           9,248\n",
            "      BatchNorm2d-11         [-1, 32, 128, 128]              64\n",
            "        Dropout2d-12         [-1, 32, 128, 128]               0\n",
            "       FastDeconv-13           [-1, 64, 64, 64]          18,496\n",
            "      BatchNorm2d-14           [-1, 64, 64, 64]             128\n",
            "        Dropout2d-15           [-1, 64, 64, 64]               0\n",
            "       FastDeconv-16           [-1, 64, 64, 64]          36,928\n",
            "      BatchNorm2d-17           [-1, 64, 64, 64]             128\n",
            "        Dropout2d-18           [-1, 64, 64, 64]               0\n",
            "       FastDeconv-19           [-1, 64, 64, 64]          36,928\n",
            "      BatchNorm2d-20           [-1, 64, 64, 64]             128\n",
            "        Dropout2d-21           [-1, 64, 64, 64]               0\n",
            "       FastDeconv-22          [-1, 128, 32, 32]          73,856\n",
            "      BatchNorm2d-23          [-1, 128, 32, 32]             256\n",
            "        Dropout2d-24          [-1, 128, 32, 32]               0\n",
            "       FastDeconv-25          [-1, 128, 32, 32]         147,584\n",
            "      BatchNorm2d-26          [-1, 128, 32, 32]             256\n",
            "        Dropout2d-27          [-1, 128, 32, 32]               0\n",
            "       FastDeconv-28          [-1, 128, 32, 32]         147,584\n",
            "      BatchNorm2d-29          [-1, 128, 32, 32]             256\n",
            "        Dropout2d-30          [-1, 128, 32, 32]               0\n",
            "  ConvTranspose2d-31          [-1, 128, 32, 32]         147,584\n",
            "  ConvTranspose2d-32          [-1, 128, 32, 32]         295,040\n",
            "      BatchNorm2d-33          [-1, 128, 32, 32]             256\n",
            "        Dropout2d-34          [-1, 128, 32, 32]               0\n",
            "  ConvTranspose2d-35          [-1, 128, 32, 32]         147,584\n",
            "      BatchNorm2d-36          [-1, 128, 32, 32]             256\n",
            "        Dropout2d-37          [-1, 128, 32, 32]               0\n",
            "  ConvTranspose2d-38           [-1, 64, 32, 32]          73,792\n",
            "      BatchNorm2d-39           [-1, 64, 32, 32]             128\n",
            "        Dropout2d-40           [-1, 64, 32, 32]               0\n",
            "  ConvTranspose2d-41           [-1, 64, 64, 64]          36,928\n",
            "  ConvTranspose2d-42           [-1, 64, 64, 64]          73,792\n",
            "      BatchNorm2d-43           [-1, 64, 64, 64]             128\n",
            "        Dropout2d-44           [-1, 64, 64, 64]               0\n",
            "  ConvTranspose2d-45           [-1, 64, 64, 64]          36,928\n",
            "      BatchNorm2d-46           [-1, 64, 64, 64]             128\n",
            "        Dropout2d-47           [-1, 64, 64, 64]               0\n",
            "  ConvTranspose2d-48           [-1, 32, 64, 64]          18,464\n",
            "      BatchNorm2d-49           [-1, 32, 64, 64]              64\n",
            "        Dropout2d-50           [-1, 32, 64, 64]               0\n",
            "  ConvTranspose2d-51         [-1, 32, 128, 128]           9,248\n",
            "  ConvTranspose2d-52         [-1, 32, 128, 128]          18,464\n",
            "      BatchNorm2d-53         [-1, 32, 128, 128]              64\n",
            "        Dropout2d-54         [-1, 32, 128, 128]               0\n",
            "  ConvTranspose2d-55         [-1, 16, 128, 128]           4,624\n",
            "      BatchNorm2d-56         [-1, 16, 128, 128]              32\n",
            "        Dropout2d-57         [-1, 16, 128, 128]               0\n",
            "  ConvTranspose2d-58         [-1, 16, 256, 256]           2,320\n",
            "  ConvTranspose2d-59         [-1, 16, 256, 256]           4,624\n",
            "      BatchNorm2d-60         [-1, 16, 256, 256]              32\n",
            "        Dropout2d-61         [-1, 16, 256, 256]               0\n",
            "  ConvTranspose2d-62          [-1, 2, 256, 256]             290\n",
            "       LogSoftmax-63          [-1, 2, 256, 256]               0\n",
            "================================================================\n",
            "Total params: 1,353,458\n",
            "Trainable params: 1,353,458\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 2768896.00\n",
            "Forward/backward pass size (MB): 180.50\n",
            "Params size (MB): 5.16\n",
            "Estimated Total Size (MB): 2769081.66\n",
            "----------------------------------------------------------------\n",
            "NETWORK OK\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:303: UserWarning: This overload of addmm is deprecated:\n",
            "\taddmm(Number beta, Tensor input, Number alpha, Tensor mat1, Tensor mat2, *, Tensor out)\n",
            "Consider using one of the following signatures instead:\n",
            "\taddmm(Tensor input, Tensor mat1, Tensor mat2, *, Number beta, Number alpha, Tensor out) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeLsY037tCDT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e24b7a12-0f42-474d-9435-3c2ccbbe9175"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print('Number of trainable parameters:', count_parameters(net))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of trainable parameters: 1353458\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7dfDWGCtCDb"
      },
      "source": [
        "# net.load_state_dict(torch.load('net-best_epoch-1_fm-0.7394933126157746.pth.tar'))\n",
        "\n",
        "def train(n_epochs = N_EPOCHS, save = True):\n",
        "    t = np.linspace(1, n_epochs, n_epochs)\n",
        "    \n",
        "    epoch_train_loss = 0 * t\n",
        "    epoch_train_accuracy = 0 * t\n",
        "    epoch_train_change_accuracy = 0 * t\n",
        "    epoch_train_nochange_accuracy = 0 * t\n",
        "    epoch_train_precision = 0 * t\n",
        "    epoch_train_recall = 0 * t\n",
        "    epoch_train_Fmeasure = 0 * t\n",
        "    epoch_test_loss = 0 * t\n",
        "    epoch_test_accuracy = 0 * t\n",
        "    epoch_test_change_accuracy = 0 * t\n",
        "    epoch_test_nochange_accuracy = 0 * t\n",
        "    epoch_test_precision = 0 * t\n",
        "    epoch_test_recall = 0 * t\n",
        "    epoch_test_Fmeasure = 0 * t\n",
        "    \n",
        "#     mean_acc = 0\n",
        "#     best_mean_acc = 0\n",
        "    fm = 0\n",
        "    best_fm = 0\n",
        "    \n",
        "    lss = 1000\n",
        "    best_lss = 1000\n",
        "    \n",
        "    plt.figure(num=1)\n",
        "    plt.figure(num=2)\n",
        "    plt.figure(num=3)\n",
        "    \n",
        "    \n",
        "    optimizer = torch.optim.Adam(net.parameters(), weight_decay=1e-4)\n",
        "#     optimizer = torch.optim.Adam(net.parameters(), lr=0.0005)\n",
        "        \n",
        "    \n",
        "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.95)\n",
        "    \n",
        "    \n",
        "    for epoch_index in tqdm(range(n_epochs)):\n",
        "        net.train()\n",
        "        print('Epoch: ' + str(epoch_index + 1) + ' of ' + str(N_EPOCHS))\n",
        "\n",
        "        tot_count = 0\n",
        "        tot_loss = 0\n",
        "        tot_accurate = 0\n",
        "        class_correct = list(0. for i in range(2))\n",
        "        class_total = list(0. for i in range(2))\n",
        "#         for batch_index, batch in enumerate(tqdm(data_loader)):\n",
        "        for batch in train_loader:\n",
        "            I1 = Variable(batch['I1'].float().cuda())\n",
        "            I2 = Variable(batch['I2'].float().cuda())\n",
        "            label = torch.squeeze(Variable(batch['label'].cuda()))\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = net(I1, I2)\n",
        "            loss = criterion(output, label.long())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "        scheduler.step()\n",
        "\n",
        "\n",
        "        epoch_train_loss[epoch_index], epoch_train_accuracy[epoch_index], cl_acc, pr_rec = test(train_dataset)\n",
        "        epoch_train_nochange_accuracy[epoch_index] = cl_acc[0]\n",
        "        epoch_train_change_accuracy[epoch_index] = cl_acc[1]\n",
        "        epoch_train_precision[epoch_index] = pr_rec[0]\n",
        "        epoch_train_recall[epoch_index] = pr_rec[1]\n",
        "        epoch_train_Fmeasure[epoch_index] = pr_rec[2]\n",
        "        \n",
        "#         epoch_test_loss[epoch_index], epoch_test_accuracy[epoch_index], cl_acc, pr_rec = test(test_dataset)\n",
        "        epoch_test_loss[epoch_index], epoch_test_accuracy[epoch_index], cl_acc, pr_rec = test(test_dataset)\n",
        "        epoch_test_nochange_accuracy[epoch_index] = cl_acc[0]\n",
        "        epoch_test_change_accuracy[epoch_index] = cl_acc[1]\n",
        "        epoch_test_precision[epoch_index] = pr_rec[0]\n",
        "        epoch_test_recall[epoch_index] = pr_rec[1]\n",
        "        epoch_test_Fmeasure[epoch_index] = pr_rec[2]\n",
        "\n",
        "        plt.figure(num=1)\n",
        "        plt.clf()\n",
        "        l1_1, = plt.plot(t[:epoch_index + 1], epoch_train_loss[:epoch_index + 1], label='Train loss')\n",
        "        l1_2, = plt.plot(t[:epoch_index + 1], epoch_test_loss[:epoch_index + 1], label='Test loss')\n",
        "        plt.legend(handles=[l1_1, l1_2])\n",
        "        plt.grid()\n",
        "#         plt.gcf().gca().set_ylim(bottom = 0)\n",
        "        plt.gcf().gca().set_xlim(left = 0)\n",
        "        plt.title('Loss')\n",
        "        display.clear_output(wait=True)\n",
        "        display.display(plt.gcf())\n",
        "\n",
        "        plt.figure(num=2)\n",
        "        plt.clf()\n",
        "        l2_1, = plt.plot(t[:epoch_index + 1], epoch_train_accuracy[:epoch_index + 1], label='Train accuracy')\n",
        "        l2_2, = plt.plot(t[:epoch_index + 1], epoch_test_accuracy[:epoch_index + 1], label='Test accuracy')\n",
        "        plt.legend(handles=[l2_1, l2_2])\n",
        "        plt.grid()\n",
        "        plt.gcf().gca().set_ylim(0, 100)\n",
        "#         plt.gcf().gca().set_ylim(bottom = 0)\n",
        "#         plt.gcf().gca().set_xlim(left = 0)\n",
        "        plt.title('Accuracy')\n",
        "        display.clear_output(wait=True)\n",
        "        display.display(plt.gcf())\n",
        "\n",
        "        plt.figure(num=3)\n",
        "        plt.clf()\n",
        "        l3_1, = plt.plot(t[:epoch_index + 1], epoch_train_nochange_accuracy[:epoch_index + 1], label='Train accuracy: no change')\n",
        "        l3_2, = plt.plot(t[:epoch_index + 1], epoch_train_change_accuracy[:epoch_index + 1], label='Train accuracy: change')\n",
        "        l3_3, = plt.plot(t[:epoch_index + 1], epoch_test_nochange_accuracy[:epoch_index + 1], label='Test accuracy: no change')\n",
        "        l3_4, = plt.plot(t[:epoch_index + 1], epoch_test_change_accuracy[:epoch_index + 1], label='Test accuracy: change')\n",
        "        plt.legend(handles=[l3_1, l3_2, l3_3, l3_4])\n",
        "        plt.grid()\n",
        "        plt.gcf().gca().set_ylim(0, 100)\n",
        "#         plt.gcf().gca().set_ylim(bottom = 0)\n",
        "#         plt.gcf().gca().set_xlim(left = 0)\n",
        "        plt.title('Accuracy per class')\n",
        "        display.clear_output(wait=True)\n",
        "        display.display(plt.gcf())\n",
        "\n",
        "        plt.figure(num=4)\n",
        "        plt.clf()\n",
        "        l4_1, = plt.plot(t[:epoch_index + 1], epoch_train_precision[:epoch_index + 1], label='Train precision')\n",
        "        l4_2, = plt.plot(t[:epoch_index + 1], epoch_train_recall[:epoch_index + 1], label='Train recall')\n",
        "        l4_3, = plt.plot(t[:epoch_index + 1], epoch_train_Fmeasure[:epoch_index + 1], label='Train Dice/F1')\n",
        "        l4_4, = plt.plot(t[:epoch_index + 1], epoch_test_precision[:epoch_index + 1], label='Test precision')\n",
        "        l4_5, = plt.plot(t[:epoch_index + 1], epoch_test_recall[:epoch_index + 1], label='Test recall')\n",
        "        l4_6, = plt.plot(t[:epoch_index + 1], epoch_test_Fmeasure[:epoch_index + 1], label='Test Dice/F1')\n",
        "        plt.legend(handles=[l4_1, l4_2, l4_3, l4_4, l4_5, l4_6])\n",
        "        plt.grid()\n",
        "        plt.gcf().gca().set_ylim(0, 1)\n",
        "#         plt.gcf().gca().set_ylim(bottom = 0)\n",
        "#         plt.gcf().gca().set_xlim(left = 0)\n",
        "        plt.title('Precision, Recall and F-measure')\n",
        "        display.clear_output(wait=True)\n",
        "        display.display(plt.gcf())\n",
        "        \n",
        "        \n",
        "#         mean_acc = (epoch_test_nochange_accuracy[epoch_index] + epoch_test_change_accuracy[epoch_index])/2\n",
        "#         if mean_acc > best_mean_acc:\n",
        "#             best_mean_acc = mean_acc\n",
        "#             save_str = 'net-best_epoch-' + str(epoch_index + 1) + '_acc-' + str(mean_acc) + '.pth.tar'\n",
        "#             torch.save(net.state_dict(), save_str)\n",
        "        \n",
        "        \n",
        "#         fm = pr_rec[2]\n",
        "        fm = epoch_train_Fmeasure[epoch_index]\n",
        "        if fm > best_fm:\n",
        "            best_fm = fm\n",
        "            save_str = 'net-best_epoch-' + str(epoch_index + 1) + '_fm-' + str(fm) + '.pth.tar'\n",
        "            torch.save(net.state_dict(), save_str)\n",
        "        \n",
        "        lss = epoch_train_loss[epoch_index]\n",
        "        if lss < best_lss:\n",
        "            best_lss = lss\n",
        "            save_str = 'net-best_epoch-' + str(epoch_index + 1) + '_loss-' + str(lss) + '.pth.tar'\n",
        "            torch.save(net.state_dict(), save_str)\n",
        "            \n",
        "            \n",
        "#         print('Epoch loss: ' + str(tot_loss/tot_count))\n",
        "        if save:\n",
        "            im_format = 'png'\n",
        "    #         im_format = 'eps'\n",
        "\n",
        "            plt.figure(num=1)\n",
        "            plt.savefig(net_name + '-01-loss.' + im_format)\n",
        "\n",
        "            plt.figure(num=2)\n",
        "            plt.savefig(net_name + '-02-accuracy.' + im_format)\n",
        "\n",
        "            plt.figure(num=3)\n",
        "            plt.savefig(net_name + '-03-accuracy-per-class.' + im_format)\n",
        "\n",
        "            plt.figure(num=4)\n",
        "            plt.savefig(net_name + '-04-prec-rec-fmeas.' + im_format)\n",
        "        \n",
        "    out = {'train_loss': epoch_train_loss[-1],\n",
        "           'train_accuracy': epoch_train_accuracy[-1],\n",
        "           'train_nochange_accuracy': epoch_train_nochange_accuracy[-1],\n",
        "           'train_change_accuracy': epoch_train_change_accuracy[-1],\n",
        "           'test_loss': epoch_test_loss[-1],\n",
        "           'test_accuracy': epoch_test_accuracy[-1],\n",
        "           'test_nochange_accuracy': epoch_test_nochange_accuracy[-1],\n",
        "           'test_change_accuracy': epoch_test_change_accuracy[-1]}\n",
        "    \n",
        "    print('pr_c, rec_c, f_meas, pr_nc, rec_nc')\n",
        "    print(pr_rec)\n",
        "    \n",
        "    return out\n",
        "\n",
        "L = 1024\n",
        "N = 2\n",
        "\n",
        "def test(dset):\n",
        "    net.eval()\n",
        "    tot_loss = 0\n",
        "    tot_count = 0\n",
        "    tot_accurate = 0\n",
        "    \n",
        "    n = 2\n",
        "    class_correct = list(0. for i in range(n))\n",
        "    class_total = list(0. for i in range(n))\n",
        "    class_accuracy = list(0. for i in range(n))\n",
        "    \n",
        "    tp = 0\n",
        "    tn = 0\n",
        "    fp = 0\n",
        "    fn = 0\n",
        "    \n",
        "    for img_index in dset.names:\n",
        "        I1_full, I2_full, cm_full = dset.get_img(img_index)\n",
        "        \n",
        "        s = cm_full.shape\n",
        "        \n",
        "\n",
        "        steps0 = np.arange(0,s[0],ceil(s[0]/N))\n",
        "        steps1 = np.arange(0,s[1],ceil(s[1]/N))\n",
        "        for ii in range(N):\n",
        "            for jj in range(N):\n",
        "                xmin = steps0[ii]\n",
        "                if ii == N-1:\n",
        "                    xmax = s[0]\n",
        "                else:\n",
        "                    xmax = steps0[ii+1]\n",
        "                ymin = jj\n",
        "                if jj == N-1:\n",
        "                    ymax = s[1]\n",
        "                else:\n",
        "                    ymax = steps1[jj+1]\n",
        "                I1 = I1_full[:, xmin:xmax, ymin:ymax]\n",
        "                I2 = I2_full[:, xmin:xmax, ymin:ymax]\n",
        "                cm = cm_full[xmin:xmax, ymin:ymax]\n",
        "\n",
        "                I1 = Variable(torch.unsqueeze(I1, 0).float()).cuda()\n",
        "                I2 = Variable(torch.unsqueeze(I2, 0).float()).cuda()\n",
        "                cm = Variable(torch.unsqueeze(torch.from_numpy(1.0*cm),0).float()).cuda()\n",
        "\n",
        "\n",
        "                output = net(I1, I2)\n",
        "                loss = criterion(output, cm.long())\n",
        "        #         print(loss)\n",
        "                tot_loss += loss.data * np.prod(cm.size())\n",
        "                tot_count += np.prod(cm.size())\n",
        "\n",
        "                _, predicted = torch.max(output.data, 1)\n",
        "\n",
        "                c = (predicted.int() == cm.data.int())\n",
        "                for i in range(c.size(1)):\n",
        "                    for j in range(c.size(2)):\n",
        "                        l = int(cm.data[0, i, j])\n",
        "                        class_correct[l] += c[0, i, j]\n",
        "                        class_total[l] += 1\n",
        "                        \n",
        "                pr = (predicted.int() > 0).cpu().numpy()\n",
        "                gt = (cm.data.int() > 0).cpu().numpy()\n",
        "                \n",
        "                tp += np.logical_and(pr, gt).sum()\n",
        "                tn += np.logical_and(np.logical_not(pr), np.logical_not(gt)).sum()\n",
        "                fp += np.logical_and(pr, np.logical_not(gt)).sum()\n",
        "                fn += np.logical_and(np.logical_not(pr), gt).sum()\n",
        "        \n",
        "    net_loss = tot_loss/tot_count\n",
        "    net_accuracy = 100 * (tp + tn)/tot_count\n",
        "    \n",
        "    for i in range(n):\n",
        "        class_accuracy[i] = 100 * class_correct[i] / max(class_total[i],0.00001)\n",
        "\n",
        "    prec = tp / (tp + fp)\n",
        "    rec = tp / (tp + fn)\n",
        "    f_meas = 2 * prec * rec / (prec + rec)\n",
        "    prec_nc = tn / (tn + fn)\n",
        "    rec_nc = tn / (tn + fp)\n",
        "    \n",
        "    pr_rec = [prec, rec, f_meas, prec_nc, rec_nc]\n",
        "        \n",
        "    return net_loss, net_accuracy, class_accuracy, pr_rec\n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7q2B2ZsbtCDi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "47695c58-ef34-466b-bd9b-f53ec180ed12"
      },
      "source": [
        "if LOAD_TRAINED:\n",
        "    net.load_state_dict(torch.load('net_final.pth.tar'))\n",
        "    print('LOAD OK')\n",
        "else:\n",
        "    t_start = time.time()\n",
        "    out_dic = train()\n",
        "    t_end = time.time()\n",
        "    print(out_dic)\n",
        "    print('Elapsed time:')\n",
        "    print(t_end - t_start)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU5dn/8c9FVpAQVlEISHyKKEsWCCAgEkQErQVE2rqDG6KPpbaPCnVBxVqltbWKPgL9FVEfrSBW0LoWJaIisiiigCwqahCVNSRAIIT798c5pJOQkEkyScjJ9/165cXMue8557rODNecuc+ce8w5h4iI1H0NajsAERGJDBV0EZGAUEEXEQkIFXQRkYBQQRcRCQgVdBGRgFBBr+fM7FIzezOMftPM7M6aiKmmmdksM/u9fzvTzLJrersikaCCfgwzs01mts/M8szsB78ANI7kNpxzzzjnzgmj3zjn3L2R3HZpzCzLzPL9nLeZ2T/N7MTq3u6xxszGmFmhvx8O/z1a23HJsU0F/dj3M+dcY6A7kAHcUbKDmUXXeFTV60Y/558AjYEHazme2vKBc65xyN+NtR1QpJhZVG3HEEQq6HWEc24z8BrQFcDMnJn9t5ltADb4y843s5VmtsvMFptZyuHHm1k7/2h3q5ltP3y05x8JvuffNjN7yMx+NLPdZvapmR3eXrHhATO71sw2mtkOM3vJzNqEtDkzG2dmG/xYHjMzq0TOu4B5QFrIuk81s3/7211nZr8IaWtoZn82s6/NLMfM3jOzhn7b82b2vb98kZl1qWg8/noeNrNv/f2zwsz6h7TdbWZzzOwpM8s1s9VmlhHSnm5mH/lts4H4ysRQSkyZZpZtZrf6z90WMxthZueZ2Xp/X90W0r+BmU00sy/818IcM2se0l7mvvLXucbPYbOZ3ewvL3odhfR1ZvYT//YsM3vczF41sz3AQDNrY2Yv+K/Jr8xsfCT2R32mgl5HmFk74Dzg45DFI4DeQGczSwdmAtcBLYDpwEtmFucfDf0L+BroALQFnitlM+cAZwKnAInAL4DtpcRyFnC/336iv96S6zsf6Amk+P2GVCLnFsBIYKN//zjg38CzwPHARcD/mlln/yEPAj2AvkBz4FbgkN/2GtDRf9xHwDMVjce3DO8Nprkfx/NmFlqYh+Hti6bAS8DhN85YvDenp/3HPg9cWMkYSnMC3htEW2AS8DfgMrz90R+408yS/b6/wnvtDADaADuBx0LWdbR99XfgOudcAt7BxdsViPES4D4gAVgMvAx84sc8CLjJzCr8OpEQzjn9HaN/wCYgD9iFVzT/F2jotzngrJC+jwP3lnj8Orz/tH2ArUB0KdsYA7zn3z4LWA+cDjQo0W8W8Hv/9t+BP4a0NQYKgA4hsZ0R0j4HmBhmzlnAXiDHX89KoL3f9kvg3RL9pwN34R2c7ANSw9hGU3/diaXklglkV+A52nl4m8DdwIKQts7APv/2mcB3gIW0Lz683TKel4P+c3/47/Qy+mb6uUf59xP8/HqH9FkBjPBvrwUGhbSd6D9/pb0+Su6rb/AOGpqU9ToKWeaAn4Ts46dC2noD35To/zvgidr+f1eX/3SEfuwb4Zxr6pw7yTl3g3NuX0jbtyG3TwL+xx/i2GVmu4B2eEdg7YCvnXMHj7Yh59zbeEeUjwE/mtkMM2tSStc2eG8whx+Xh3ck3zakz/cht/fiFf1wjXfOJeId3TcDkkJy7F0ix0vxjk5b4h2hflFyZWYWZWYP+EMMu/HeKPEfUyFmdrOZrfWHI3bhfZIJXU/JvOPNO8fRBtjs/Mrl+5qjW+I/94f/lphZews5URrSd7tzrtC/ffg18kNI+z7+8xycBLwYsg/XAoVA6zD21YV4nxS/NrN3zKxPOTmEKvl6bVPiubwNaF2B9UkJKuh1W2hx+Ba4r0QBaOSc+4ff1t7COHnqnHvEOdcD7+jyFOCWUrp9h/cfEigaCmkBbK5CLqXF8inwe+DwGPy3wDslcmzsnLse2AbkA/9VyqouAYYDZ+MV4A6HQ69IPP54+a14Q0jNnHNN8T5JhLOeLUDbEucS2ldk+wDOuW9cyInSij7e9y1wbon9GO+88zRH3VfOuWXOueF4wzHz8D59AewBGh3egJmdUFr4JWL4qkQMCc658yqZk6CCHiR/A8aZWW/zHGdmPzWzBGApXkF5wF8eb2b9Sq7AzHr6j4/B+w+az3/GoEP9A7jSzNLMLA74A/Chc25TeUGaWQf/ZFmHMPN6Eu+obRjeeYBTzOxyM4vx/3qa2WnOuUN45xD+4p9sizKzPn58CcB+vE8Rjfx4KyMBbxhkKxBtZpOA0j7BlOYD/7Hj/bhHAr0qGUdVTQPuM7OTAMyslZkN99vK3FdmFmvedQuJzrkCYDf/eX18AnTxXxPxeMNPR7MUyDWzCeadzI4ys65m1jNSSdZHKugB4ZxbDlyLN2SyE+9E4hi/rRD4Gd7XAL8BsvHGo0tqgvfGsBNvOGA78KdStrUAuBN4Ae+N4r/wTlCGo52/7rCO5p1zB4CHgTudc7l4J24vwvuU8D0wBYjzu98MfIp34nKH39YAeCpkm2uAJWHGWtIbwOt45xm+xnvD+/aojyiex0i852QH3v7/ZyXjqKqH8U7YvmlmuXj7o7ffVt6+uhzY5A/HjMMb8sI5tx6YDCzA+9bVexyF/5o8H+8E81d4n7D+H96nAqkkKz6kJ1K9zOwOYKtzbnptxyISNCroIiIBUe6Qi5nNNO9ihc/KaDcze8S8i0xWmVn3yIcpIiLlCWcMfRYw9Cjt5+JdhNARGIv3fWgREalh5RZ059wivJM4ZRmOd8GAc84tAZpaPZxMSUSktkViUqe2FD/Tn+0v21Kyo5mNxTuKp2HDhj3atWsXgc3XrEOHDtGgQf36clB9y7m+5QvKuS5Zv379Nudcq9LaanSWPufcDGAGQEZGhlu+fHlNbj4isrKyyMzMrO0walR9y7m+5QvKuS4xszKvMI7E29NmvO8WH5ZEhK8YFBGR8kWioL8EXOF/2+V0IMc5d8Rwi4iIVK9yh1zM7B94s7m1NO+nue4CYgCcc9OAV/Em69mINxnRldUVrIiIlC2cyZouLqfdAf8dsYhEpNoUFBSQnZ1Nfn5+seWJiYmsXbu2lqKqHcd6zvHx8SQlJRETExP2Y4L202UichTZ2dkkJCTQoUMHQid+zM3NJSEhoRYjq3nHcs7OObZv3052djbJycnlP8BX976zIyKVlp+fT4sWLYoVczn2mBktWrQ44pNUeVTQReoZFfO6oTLPkwq6iEhAqKCLSI3Zvn07aWlppKWlccIJJ9C2bdui+wcOHDjqY5cvX8748eNrKNKyfffdd4waNeqoffr27VtD0RSnk6IiUmNatGjBypUrAbj77rtp3LgxN998c1H7wYMHiY4uvSxlZGSQkZER8ZiOts3StGnThrlz5x61z+LFi6saVqXoCF1EatWYMWMYN24cvXv35tZbb2Xp0qX06dOH9PR0+vbty7p16wDvUv3zzz8f8N4MrrrqKjIzMzn55JN55JFHSl1348aN+c1vfkOXLl0YNGgQW7duBSAzM5MJEyaQkZHBww8/zIoVKxgwYAA9evRgyJAhbNniXRu5ceNGzj77bFJTU+nevTtffPEFmzZtomvXrgCsXr2aXr16kZaWRkpKChs2bCjaLnjfVrnlllvo2rUr3bp1Y/bs2UW5ZGZmMmrUKE499VQuvfRSIvHbFDpCF6mn7nl5NWu+2w1AYWEhUVFRVV5n5zZNuOtnXSr8uOzsbBYvXkxUVBS7d+/m3XffJTo6mgULFnDbbbfxwgsvHPGYzz//nIULF5Kbm0unTp24/vrrj/jO9p49e8jIyOChhx5i8uTJ3HPPPTz66KMAHDhwgOXLl1NQUMCAAQOYP38+rVq1Yvbs2dx+++3MnDmTSy+9lIkTJ3LBBReQn5/PoUOH+PHHH4vWP23aNH79619z6aWXcuDAAQoLC4tt/5///CcrV67kk08+Ydu2bfTs2ZMzzzwTgI8//pjVq1fTpk0b+vXrx/vvv88ZZ5xR4X0XSgVdRGrdz3/+86I3lJycHEaPHs2GDRswMwoKCkp9zE9/+lPi4uKIi4vj+OOP54cffiApKalYnwYNGvDLX3o/n3vZZZcxcuTIorYLL7wQgHXr1vHZZ58xePBgwHtzO/HEE8nNzWXz5s1ccMEFgHehT0l9+vThvvvuIzs7m5EjR9KxY8di7e+99x4XX3wxUVFRtG7dmgEDBrBs2TKaNGlCr169iuJNS0tj06ZNKugiUjmhR9K1fZHNcccdV3T7zjvvZODAgbz44ots2rSpzBkR4+Liim5HRUVx8ODBcrcT+lXARo0aAd6wSJcuXfjggw+K9c3NzS13fZdccgm9e/fmlVde4bzzzmP69OmcddZZ5T6usvGXR2PoInJMycnJoW3btgDMmjWrSus6dOhQ0QnMZ599ttQj4E6dOrF169aigl5QUMDq1atJSEggKSmJefPmAbB//3727t1b7LFffvklJ598MuPHj2f48OGsWrWqWHv//v2ZPXs2hYWFbN26lUWLFtGrV68q5XQ0Kugicky59dZb+d3vfkd6enqVj1qPO+44li5dSteuXXn77beZNGnSEX1iY2OZO3cuEyZMIDU1lbS0tKJvqTz99NM88sgjpKSk0LdvX77//vtij50zZw5du3YlLS2Nzz77jCuuuKJY+wUXXEBKSgqpqamcddZZ/PGPf+SEE06oUk5HY5E4s1oZ+oGLuqO+5RzkfNeuXctpp512xPLaHnKpLo0bNyYvL6/UtrqQc2nPl5mtcM6V+v1NHaGLiASECrqIBFZZR+dBpYIuIhIQKugiIgGhgi4iEhAq6CIiAaGCLiI1JgjT54ZOEjZr1ixuvPHGWo7oP3Tpv4jUmNqcPjdSE5Ady3SELiK1qrqnz/2f//kfUlNT+eCDD/i///u/ouluf/3rXxfNjvj666/TvXt3UlNTGTRoEECZcRzLdIQuUl+9NhG+/xSAhoUHISoC5eCEbnDuAxV+WHVOn9u7d2/+/Oc/s3btWqZMmcL7779PTEwM11xzDc888wznnnsu1157LYsWLSI5OZkdO3YAcOqpp4YVx7FEBV1Eal11TZ8bFRVVNE3uW2+9xYoVK+jZsyfgFfukpCSWLFnCmWeeSXJyMgDNmzevUBzHEhV0kfoq5Eh6X0Cnz42Pjy96o3DOMXr0aO6//37gP3O5vPzyy6WuP9w4jiUaQxeRY0okp88NNWjQIObOnVv0i0M7duzg66+/5vTTT2fRokV89dVXRcurM47qpIIuIseUSE6fG6pz5878/ve/55xzziElJYURI0awZcsWWrVqxYwZMxg5ciSpqalFv3BUXXFUJ02fW0FBnlq1LPUt5yDnW9+mzz2aupCzps8VEamnVNBFRAJCBV1EJCBU0EVEAkIFXUQkIFTQRUQCQgVdRGpMTU+f26FDB7p160a3bt3o3Lkzd9xxB/n5+QBs2bKFUaNGVTqXJUuWcO2115KVlUViYmJRHmeffTYAixYtonv37kRHRzN37txKb6ciwrr038yGAg8DUcD/c849UKK9PfAk0NTvM9E592qEYxWROq42ps9duHAhLVu2JC8vj7Fjx3Ldddfx5JNPcuKJJ1ap0L722msMHToUgP79+/Ovf/2rWHv79u2ZNWsWDz74YKW3UVHlHqGbWRTwGHAu0Bm42Mw6l+h2BzDHOZcOXAT8b6QDFZFgqs7pc0M1btyYadOmMW/evKLL/rt27Qp4c6XffPPNdO3alZSUFKZOnQrAihUrGDBgAD169GDIkCFs2bKlaH1vvfVW0dF4aTp06EBKSgoNGtTcQEg4R+i9gI3OuS8BzOw5YDiwJqSPA5r4txOB7yIZpIhE3pSlU/h8x+dA5H784dTmpzKh14QKP666ps8tqUmTJiQnJ7Nhw4ZiE4LNmDGDTZs2sXLlSqKjo9mxYwcFBQX86le/Yv78+bRq1YrZs2dz++23M3PmTLZt20ZMTAyJiYkAvPvuu6SlpQHezJG33357hfdBJIRT0NsC34bczwZ6l+hzN/Cmmf0KOA4o9W3LzMYCYwFat25NVlZWBcOtfXl5eXUy7qqobzkHOd/ExERyc3MBOHDgQNEPPDjnim5XxYEDB4rWX579+/cTExNDQUEB559/Pnv37gVg8+bN3HrrrXzxxRdF09bm5uayd+9eDh48SG5uLvv37+fss8/mwIEDxMXF0bJlS7744ouiybQOc86Rl5dXbGbGwsJC9uzZQ8OGDTl06BC5ubm8/vrrXHXVVezbtw+AmJgYPvroIz777LOiH7woLCykdevW5ObmMn/+fAYMGFAUV58+fXj++eeLthG6DwoKCti3b1/Y+yVUfn5+hV6LkZo+92JglnPuz2bWB3jazLo65w6FdnLOzQBmgDeXS12cLyPI83yUpb7lHOR8165dWzR/yZ1n3Fm0vDbmNTk8l3lMTAwtW7Ys2v6UKVMYPHgwL7/8ctG0tQkJCTRq1Ijo6GgSEhKIi4ujcePGRY+JiYkhPj7+iBzMrFi/3NxcvvnmG9LT09m8eTMNGjQgISGB6OhoGjVqVOzxjRo1okuXLnzwwQdHxJ6VlcVvf/vbI+IqTUxMDA0bNqzU/o2Pjyc9PT3s/uEM7mwG2oXcT/KXhboamAPgnPsAiAdahh2FiIivuqatzcvL44YbbmDEiBE0a9asWNvgwYOZPn160ayKO3bsoFOnTmzdurWooBcUFLB69Wqcc6xatapoiOVYEk5BXwZ0NLNkM4vFO+n5Uok+3wCDAMzsNLyCvjWSgYpI/RDpaWsHDhxI165d6dWrF+3bt2f69OlH9Lnmmmto3749KSkppKam8uyzzxIbG8vcuXOZMGECqamppKWlsXjxYlasWEF6ejpmdtTtLlu2jKSkJJ5//nmuu+46unTpUuVcyuWcK/cPOA9YD3wB3O4vmwwM8293Bt4HPgFWAueUt84ePXq4umjhwoW1HUKNq285BznfNWvWlLp89+7dNRxJ7atszvfee6/7xz/+EeFoSlfa8wUsd2XU1bDG0J33nfJXSyybFHJ7DdCviu8tIiLHvDvuuKO2QyiTrhQVEQkIFXQRkYBQQRcRCQgVdBGRgFBBFxEJCBV0EakxVZk+F7wrNBcvXlwDkf7HpEmTWLBgQZnt06ZN46mnnqrBiMoWqUv/RUTKVd70ueXJysqicePG9O3bt1LbP9r0vGWZPHnyUdvHjRtXqViqg47QRaRWlTVF7SOPPELnzp1JSUnhoosuYtOmTUybNo2HHnqItLQ03n333WLrufvuu7n88svp06cPHTt25G9/+xvgvQn079+fYcOG0blzZwoLC7nlllsYMGAAKSkpxa4cnTJlCt26dSM1NZWJEycC3vS+h+dNnzhxYlFMh9+I7r777qI5z1euXMnpp59OSkoKF1xwATt37gQgMzOTCRMm0KtXL0455ZQjYo8UHaGL1FPf/+EP7F/rTZ97sLCQHRGYPjfutFM54bbbwu7vnCtzitoHHniAr776iri4OHbt2kXTpk0ZN27cUY/qV61axZIlS9izZw/p6en89Kc/BSiaOTE5OZkZM2aQmJjIO++8Q2xsLP369eOcc87h888/Z/78+Xz44Yc0atSIHTt2FFv39u3befHFF/n8888xM3bt2nXE9q+44gqmTp3KgAEDmDRpEvfccw9//etfAe/TwdKlS3n11Ve55557jjqMU1kq6CJSa/bv389nn33G4MGDAW+K2hNPPBGAlJQULr30UkaMGMGIESPCWt/w4cNp2LAhDRs2ZODAgSxdupSmTZvSq1cvkpOTAXjzzTdZtWoVc+bMoUGDBuTk5LBhwwYWLFjAlVdeSaNGjQBo3rx5sXUnJiYSHx/P1Vdfzfnnn1/0YxuH5eTksGvXLgYMGADA6NGj+fnPf17UPnLkSAB69OjBpk2bKrinwqOCLlJPhR5J18b0ueAdoZc1Re0rr7zCokWLePnll7nvvvv49NNPy11fyQmzDt8P/TEL5xxTp06lb9++xXJ+4403jrru6Oholi5dyltvvcXcuXN59NFHefvtt8uN6bDDc7JHRUVFZNKx0mgMXURqTVxcXKlT1B46dIhvv/2WgQMHMmXKFHJycsjLyyMhIeGoPxQxf/588vPz2b59O1lZWfTs2fOIPkOGDOHxxx+noKAAgPXr17Nnzx4GDx7ME088UfRDGyWHXPLy8sjJyeG8887joYce4pNPPinWnpiYSLNmzYrGx59++umio/WaoiN0Eak1DRo0YO7cuYwfP56cnBwOHjzITTfdxCmnnMJll11GTk4OzjnGjx9P06ZN+dnPfsaoUaOYP38+U6dOpX///sXWl5KSwsCBA9m2bRt33nknbdq0Yf369cX6XHPNNWzatIn+/ftjZrRq1Yp58+YxdOhQVq5cSUZGBrGxsZx33nn84Q9/KHpcbm4uw4cPJz8/H+ccf/nLX47I58knn2TcuHHs3buXk08+mSeeeKJ6dlwZzJuNseZlZGS45cuX18q2qyLIv2ZTlvqWc5DzXbt2LaeddtoRy2tryCWSKvo1yLqQc2nPl5mtcM5llNZfQy4iIgGhIRcRCYS77767tkOodTpCFxEJCBV0EZGAUEEXEQkIFXQRkYBQQReRGlMXp8/NzMzk8FesO3TowLZt22p0+xWhb7mISI2pqelzKzNNbhDoCF1EalWkp8/t168fl19+OVu3buXCCy+kZ8+e9OzZk/fffx/wLuG/8sori6a5feGFFwC4/vrrycjIoEuXLtx11101uxMipP69hYkIAO/OWc+2b/MAb5bDqAhMn9uyXWP6/+KUsPtHevrcNWvW8N5779GwYUMuueQSfvOb33DGGWfwzTffMGTIENauXcu9995LYmIiS5YsISEhoWjO8vvuu4/mzZtTWFjIoEGDWLVqFSkpKVXeJzVJBV1Eak2kp88dNmwYDRs2BGDBggWsWbOmqG337t3k5eWxYMECnnvuuaLlzZo1A2DOnDnMmDGDgwcPsmXLFtasWaOCLiJ1Q+iRdFCmzw2dJvfQoUMsWbKE+Pj4ch/31Vdf8eCDD7Js2TKaNWvGmDFjyM/Pr1gyxwCNoYtIrYn09LmhzjnnHKZOnVp0//DJ2MGDB/PYY48VLd+5cye7d+/muOOOIzExkR9++IHXXnstglnWHBV0Eak1h6fPnTBhAqmpqaSlpbF48WIKCwu57LLL6NatG+np6cWmz33xxRdLPSla0iOPPMLy5ctJSUmhc+fOTJs2DYA77riDnTt30rt3b1JTU1m4cCGpqamkp6dz6qmncskll9CvX7+aSD/iNH1uBQV5atWy1Lecg5xvkKfPrai6kLOmzxURqadU0EVEAkIFXUQkIFTQRUQCQgVdRCQgwiroZjbUzNaZ2UYzm1hGn1+Y2RozW21mz0Y2TBERKU+5Bd3MooDHgHOBzsDFZta5RJ+OwO+Afs65LsBN1RCriNRx1Tl97qxZs2jVqhXp6el07NiRIUOGFOs7adIkFixYUOnYzz33XLKzs8nMzKRTp05Fcc+dOxeAq666iuOPP56uXbtWehtVFc6l/72Ajc65LwHM7DlgOLAmpM+1wGPOuZ0AzrkfIx2oiNR91T197i9/+UseffRRABYuXMjIkSNZuHAhp512GpMnT6503Pv27WP79u0kJSUB8Mwzz5CRUfyr4GPGjOHGG2/kiiuuqPR2qiqcgt4W+DbkfjbQu0SfUwDM7H0gCrjbOfd6yRWZ2VhgLEDr1q3JysqqRMi1Ky8vr07GXRX1Lecg55uYmFjqpfOFhYVhX1IfKfv37ycmJoZFixZx2223sWfPHpo3b860adM44YQTePzxx5k5cybR0dF06tSJe+65h8cff5yoqCieeuop/vSnPxUr7Pn5+Rw4cKAoj4yMDEaPHs2jjz7KAw88wLhx4xg6dCgjRoxgxYoV3Hrrrezbt4/Y2FhefvllGjVqxF133cW7777LgQMHuPbaa7nqqqsAePPNN+nbty+5ubkUFhayZ8+eI/ZXeno6X3/9NYcOHYrYvszPz6/QazFSk3NFAx2BTCAJWGRm3Zxzu0I7OedmADPAu1K0Ll6NF+SrCMtS33IOcr5r164tujpy4awZ/Pj1lwAUHiwkKrrq0+cef9LJDBwzNqy+cXFxxMbGMnHixGLT595///3MnDmTv/71r0dMn3v99deXeVQfHx9PbGxssas/+/Tpw/Tp00lISCAmJoaGDRsSFxfHVVddxcyZM8nMzGT37t00atSImTNn0qpVKz766CP2799Pv379GDZsGMnJybzzzjuMGDGChIQEoqKiGDt2bNGsjm+99RYtWrQAoHHjxjRo0CBiV6DGx8eTnp4edv9wCvpmoF3I/SR/Wahs4EPnXAHwlZmtxyvwy8KORETqnUhPn1tSaVObrFu3jhNPPJEePXoA0KRJE8A7Cl+1alXRmHhOTg4bNmwgOTmZ999/nwcffLBoHaUNuRwLwinoy4COZpaMV8gvAi4p0WcecDHwhJm1xBuC+TKSgYpIZIUeSQdl+tySPv7441LnrikrlqlTpzJkyJBiy7/88kvatWtHbGxshbdf08r9lotz7iBwI/AGsBaY45xbbWaTzWyY3+0NYLuZrQEWArc457ZXV9AiEgzVOX3uO++8w4wZM7j22muLLe/UqRNbtmxhxYoVgPdmdvDgQYYMGcLjjz9OQUEBAOvXr2fPnj289tprDB06NIJZV5+wxtCdc68Cr5ZYNinktgN+6/+JiITl8PS548ePJycnh4MHD3LTTTdxyimncNlll5GTk4Nzrtj0uaNGjWL+/PlMnTqV/v37F1vf7Nmzee+999i7dy/Jycm88MILRxyhx8bGMnv2bG644QYOHDhAw4YNWbBgAddccw2bNm2ie/fuOOdo1aoV8+bN4/XXXy82r3pZLr74YrKysti2bRtJSUncc889XH311RHdX+XR9LkVFOQTZmWpbzkHOV9Nn/sf4eR8+ORobdUqTZ8rIhIhcXFxtVbMK0MFXUQkIFTQReqZ2hpmlYqpzPOkgi5Sj8THx7N9+3YV9WOcc47t27cTHx9focdF6rNDI98AAAmySURBVEpREakDkpKSyM7OZuvWrcWW5+fnV7h41HXHes7x8fFFc8eESwVdpB6JiYkhOTn5iOVZWVkVusQ8CIKYs4ZcREQCQgVdRCQgVNBFRAJCBV1EJCBU0EVEAkIFXUQkIFTQRUQCQgVdRCQgVNBFRAJCBV1EJCBU0EVEAkIFXUQkIFTQRUQCQgVdRCQgVNBFRAJCBV1EJCBU0EVEAkIFXUQkIFTQRUQCQgVdRCQgVNBFRAJCBV1EJCBU0EVEAkIFXUQkIFTQRUQCQgVdRCQgVNBFRAJCBV1EJCDCKuhmNtTM1pnZRjObeJR+F5qZM7OMyIUoIiLhKLegm1kU8BhwLtAZuNjMOpfSLwH4NfBhpIMUEZHyhXOE3gvY6Jz70jl3AHgOGF5Kv3uBKUB+BOMTEZEwRYfRpy3wbcj9bKB3aAcz6w60c869Yma3lLUiMxsLjAVo3bo1WVlZFQ64tuXl5dXJuKuivuVc3/IF5RwU4RT0ozKzBsBfgDHl9XXOzQBmAGRkZLjMzMyqbr7GZWVlURfjror6lnN9yxeUc1CEM+SyGWgXcj/JX3ZYAtAVyDKzTcDpwEs6MSoiUrPCKejLgI5mlmxmscBFwEuHG51zOc65ls65Ds65DsASYJhzbnm1RCwiIqUqt6A75w4CNwJvAGuBOc651WY22cyGVXeAIiISnrDG0J1zrwKvllg2qYy+mVUPS0REKkpXioqIBIQKuohIQKigi4gEhAq6iEhAqKCLiASECrqISECooIuIBIQKuohIQKigi4gEhAq6iEhAqKCLiASECrqISECooIuIBIQKuohIQKigi4gEhAq6iEhAqKCLiASECrqISECooIuIBIQKuohIQKigi4gEhAq6iEhAqKCLiASECrqISECooIuIBIQKuohIQKigi4gEhAq6iEhAqKCLiASECrqISECooIuIBIQKuohIQKigi4gEhAq6iEhAhFXQzWyoma0zs41mNrGU9t+a2RozW2Vmb5nZSZEPVUREjqbcgm5mUcBjwLlAZ+BiM+tcotvHQIZzLgWYC/wx0oGKiMjRhXOE3gvY6Jz70jl3AHgOGB7awTm30Dm317+7BEiKbJgiIlKe6DD6tAW+DbmfDfQ+Sv+rgddKazCzscBYgNatW5OVlRVelMeQvLy8Ohl3VdS3nOtbvqCcgyKcgh42M7sMyAAGlNbunJsBzADIyMhwmZmZkdx8jcjKyqIuxl0V9S3n+pYvKOegCKegbwbahdxP8pcVY2ZnA7cDA5xz+yMTnoiIhCucMfRlQEczSzazWOAi4KXQDmaWDkwHhjnnfox8mCIiUp5yC7pz7iBwI/AGsBaY45xbbWaTzWyY3+1PQGPgeTNbaWYvlbE6ERGpJmGNoTvnXgVeLbFsUsjtsyMcl4iIVJCuFBURCQgVdBGRgFBBFxEJCBV0EZGAUEEXEQkIFXQRkYBQQRcRCQgVdBGRgFBBFxEJCBV0EZGAUEEXEQkIFXQRkYBQQRcRCQgVdBGRgFBBFxEJCBV0EZGAUEEXEQkIFXQRkYBQQRcRCQgVdBGRgFBBFxEJCBV0EZGAUEEXEQkIFXQRkYBQQRcRCQgVdBGRgFBBFxEJCBV0EZGAUEEXEQkIFXQRkYBQQRcRCQgVdBGRgFBBFxEJCBV0EZGAUEEXEQmIsAq6mQ01s3VmttHMJpbSHmdms/32D82sQ6QDFRGRoyu3oJtZFPAYcC7QGbjYzDqX6HY1sNM59xPgIWBKpAMVEZGjC+cIvRew0Tn3pXPuAPAcMLxEn+HAk/7tucAgM7PIhSkiIuWJDqNPW+DbkPvZQO+y+jjnDppZDtAC2BbayczGAmP9u3lmtq4yQdeylpTIqx6obznXt3xBOdclJ5XVEE5Bjxjn3AxgRk1uM9LMbLlzLqO246hJ9S3n+pYvKOegCGfIZTPQLuR+kr+s1D5mFg0kAtsjEaCIiIQnnIK+DOhoZslmFgtcBLxUos9LwGj/9ijgbeeci1yYIiJSnnKHXPwx8RuBN4AoYKZzbrWZTQaWO+deAv4OPG1mG4EdeEU/qOr0kFEl1bec61u+oJwDwXQgLSISDLpSVEQkIFTQRUQCQgXdF8b0BieZ2VtmtsrMsswsKaStvZm9aWZrzWxNXZn6oIo5/9HMVvs5P1JXLiQzs5lm9qOZfVZGu/n5bPTz7h7SNtrMNvh/o0t7/LGmsvmaWZqZfeA/x6vM7Jc1G3nlVeU59tubmFm2mT1aMxFHkHOu3v/hnez9AjgZiAU+ATqX6PM8MNq/fRbwdEhbFjDYv90YaFTbOVVnzkBf4H1/HVHAB0BmbecUZt5nAt2Bz8poPw94DTDgdOBDf3lz4Ev/32b+7Wa1nU815nsK0NG/3QbYAjSt7XyqM+eQ9oeBZ4FHazuXiv7pCN0TzvQGnYG3/dsLD7f789pEO+f+DeCcy3PO7a2ZsKuk0jkDDojHeyOIA2KAH6o94ghwzi3C+yZWWYYDTznPEqCpmZ0IDAH+7Zzb4ZzbCfwbGFr9EVdNZfN1zq13zm3w1/Ed8CPQqvojrroqPMeYWQ+gNfBm9UcaeSrontKmN2hbos8nwEj/9gVAgpm1wDuS2WVm/zSzj83sT/6EZse6SufsnPsAr8Bv8f/ecM6treZ4a0pZ+yWc/VUXlZuXmfXCe/P+ogbjqk6l5mxmDYA/AzfXSlQRoIIevpuBAWb2MTAA7+rYQrzv8vf323viDWGMqaUYI63UnM3sJ8BpeFcNtwXOMrP+tRemVBf/yPVp4Ern3KHajqea3QC86pzLru1AKqtG53I5hpU7vYH/sXMkgJk1Bi50zu0ys2xgpXPuS79tHt643N9rIvAqqErO1wJLnHN5fttrQB/g3ZoIvJqVtV82A5kllmfVWFTVp8zXgZk1AV4BbveHJoKirJz7AP3N7Aa8c2GxZpbnnDviCwPHKh2he8qd3sDMWvofyQB+B8wMeWxTMzs8vngWsKYGYq6qquT8Dd6Re7SZxeAdvQdlyOUl4Ar/mxCnAznOuS14V0qfY2bNzKwZcI6/rK4rNV//NfEi3ljz3NoNMeJKzdk5d6lzrr1zrgPep9On6lIxBx2hA2FPb5AJ3G9mDlgE/Lf/2EIzuxl4y//q3grgb7WRR0VUJWe8Oe/PAj7FO0H6unPu5ZrOoTLM7B94ebX0P13dhXdSF+fcNOBVvG9BbAT2Alf6bTvM7F68N0KAyc65o514OyZUNl/gF3jfFmlhZmP8ZWOccytrLPhKqkLOdZ4u/RcRCQgNuYiIBIQKuohIQKigi4gEhAq6iEhAqKCLiASECrqISECooIuIBMT/B5FWTlUMida1AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 1/50 [10:13<8:20:56, 613.40s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 2 of 50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-8677fed8528e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mt_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mout_dic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mt_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_dic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-75a2db202472>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(n_epochs, save)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mepoch_train_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_train_accuracy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcl_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpr_rec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mepoch_train_nochange_accuracy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcl_acc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mepoch_train_change_accuracy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcl_acc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-75a2db202472>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(dset)\u001b[0m\n\u001b[1;32m    247\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m                         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m                         \u001b[0mclass_correct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m                         \u001b[0mclass_total\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpYtA84qtCDp"
      },
      "source": [
        "if not LOAD_TRAINED:\n",
        "    torch.save(net.state_dict(), 'net_final.pth.tar')\n",
        "    print('SAVE OK')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4icwmptgtCDv"
      },
      "source": [
        "\n",
        "\n",
        "def save_test_results(dset):\n",
        "    for name in tqdm(dset.names):\n",
        "        with warnings.catch_warnings():\n",
        "            I1, I2, cm = dset.get_img(name)\n",
        "            I1 = Variable(torch.unsqueeze(I1, 0).float()).cuda()\n",
        "            I2 = Variable(torch.unsqueeze(I2, 0).float()).cuda()\n",
        "            out = net(I1, I2)\n",
        "            _, predicted = torch.max(out.data, 1)\n",
        "            I = np.stack((255*cm,255*np.squeeze(predicted.cpu().numpy()),255*cm),2)\n",
        "            io.imsave(f'{net_name}-{name}.png',I)\n",
        "\n",
        "\n",
        "\n",
        "t_start = time.time()\n",
        "# save_test_results(train_dataset)\n",
        "save_test_results(test_dataset)\n",
        "t_end = time.time()\n",
        "print('Elapsed time: {}'.format(t_end - t_start))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3peRWNtxtCD0"
      },
      "source": [
        "L = 1024\n",
        "\n",
        "def kappa(tp, tn, fp, fn):\n",
        "    N = tp + tn + fp + fn\n",
        "    p0 = (tp + tn) / N\n",
        "    pe = ((tp+fp)*(tp+fn) + (tn+fp)*(tn+fn)) / (N * N)\n",
        "    \n",
        "    return (p0 - pe) / (1 - pe)\n",
        "\n",
        "def test(dset):\n",
        "    net.eval()\n",
        "    tot_loss = 0\n",
        "    tot_count = 0\n",
        "    tot_accurate = 0\n",
        "    \n",
        "    n = 2\n",
        "    class_correct = list(0. for i in range(n))\n",
        "    class_total = list(0. for i in range(n))\n",
        "    class_accuracy = list(0. for i in range(n))\n",
        "    \n",
        "    tp = 0\n",
        "    tn = 0\n",
        "    fp = 0\n",
        "    fn = 0\n",
        "    \n",
        "    for img_index in tqdm(dset.names):\n",
        "        I1_full, I2_full, cm_full = dset.get_img(img_index)\n",
        "        \n",
        "        s = cm_full.shape\n",
        "        \n",
        "        for ii in range(ceil(s[0]/L)):\n",
        "            for jj in range(ceil(s[1]/L)):\n",
        "                xmin = L*ii\n",
        "                xmax = min(L*(ii+1),s[1])\n",
        "                ymin = L*jj\n",
        "                ymax = min(L*(jj+1),s[1])\n",
        "                I1 = I1_full[:, xmin:xmax, ymin:ymax]\n",
        "                I2 = I2_full[:, xmin:xmax, ymin:ymax]\n",
        "                cm = cm_full[xmin:xmax, ymin:ymax]\n",
        "\n",
        "                I1 = Variable(torch.unsqueeze(I1, 0).float()).cuda()\n",
        "                I2 = Variable(torch.unsqueeze(I2, 0).float()).cuda()\n",
        "                cm = Variable(torch.unsqueeze(torch.from_numpy(1.0*cm),0).float()).cuda()\n",
        "\n",
        "                output = net(I1, I2)\n",
        "                    \n",
        "                loss = criterion(output, cm.long())\n",
        "                tot_loss += loss.data * np.prod(cm.size())\n",
        "                tot_count += np.prod(cm.size())\n",
        "\n",
        "                _, predicted = torch.max(output.data, 1)\n",
        "\n",
        "                c = (predicted.int() == cm.data.int())\n",
        "                for i in range(c.size(1)):\n",
        "                    for j in range(c.size(2)):\n",
        "                        l = int(cm.data[0, i, j])\n",
        "                        class_correct[l] += c[0, i, j]\n",
        "                        class_total[l] += 1\n",
        "                        \n",
        "                pr = (predicted.int() > 0).cpu().numpy()\n",
        "                gt = (cm.data.int() > 0).cpu().numpy()\n",
        "                \n",
        "                tp += np.logical_and(pr, gt).sum()\n",
        "                tn += np.logical_and(np.logical_not(pr), np.logical_not(gt)).sum()\n",
        "                fp += np.logical_and(pr, np.logical_not(gt)).sum()\n",
        "                fn += np.logical_and(np.logical_not(pr), gt).sum()\n",
        "        \n",
        "    net_loss = tot_loss/tot_count        \n",
        "    net_loss = float(net_loss.cpu().numpy())\n",
        "    \n",
        "    net_accuracy = 100 * (tp + tn)/tot_count\n",
        "    \n",
        "    for i in range(n):\n",
        "        class_accuracy[i] = 100 * class_correct[i] / max(class_total[i],0.00001)\n",
        "        class_accuracy[i] =  float(class_accuracy[i].cpu().numpy())\n",
        "\n",
        "    prec = tp / (tp + fp)\n",
        "    rec = tp / (tp + fn)\n",
        "    dice = 2 * prec * rec / (prec + rec)\n",
        "    prec_nc = tn / (tn + fn)\n",
        "    rec_nc = tn / (tn + fp)\n",
        "    \n",
        "    pr_rec = [prec, rec, dice, prec_nc, rec_nc]\n",
        "    \n",
        "    k = kappa(tp, tn, fp, fn)\n",
        "    \n",
        "    return {'net_loss': net_loss, \n",
        "            'net_accuracy': net_accuracy, \n",
        "            'class_accuracy': class_accuracy, \n",
        "            'precision': prec, \n",
        "            'recall': rec, \n",
        "            'dice': dice, \n",
        "            'kappa': k}\n",
        "\n",
        "results = test(test_dataset)\n",
        "pprint(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ifeLG8otCD8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqSuwfg2tCED"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZvn79GEtCER"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHJRkQnltCEZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRYCeSd9tCEg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
